# Projet Knapsack 0/1 - Analyse Comparative d'Algorithmes

**√âquipe :** Chaabane, Arman, Bartosz, Ahmed  
**Date :** D√©cembre 2024  
**Cours :** Analyse d'Algorithmes

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: Academic](https://img.shields.io/badge/license-Academic-green.svg)](LICENSE)

---

## üìã Table des Mati√®res

- [√Ä Propos](#√†-propos)
- [Reproduction des R√©sultats](#reproduction-des-r√©sultats)
- [Installation D√©taill√©e](#installation-d√©taill√©e)
- [Guide d'Utilisation Complet](#guide-dutilisation-complet)
- [Structure du Projet](#structure-du-projet)
- [Algorithmes Impl√©ment√©s](#algorithmes-impl√©ment√©s)
- [Donn√©es et Benchmarks](#donn√©es-et-benchmarks)
- [R√©sultats et Analyses](#r√©sultats-et-analyses)
- [Probl√®mes Connus et Limitations](#probl√®mes-connus-et-limitations)

---

## √Ä Propos

Ce projet pr√©sente une **analyse comparative exhaustive** de 16 algorithmes pour r√©soudre le probl√®me du Knapsack 0/1. Notre objectif est de comprendre **quand et pourquoi** utiliser chaque algorithme selon le contexte (taille du probl√®me, contraintes de temps, besoin d'optimalit√©).

### Caract√©ristiques Principales

- **16 algorithmes** impl√©ment√©s de z√©ro (aucune biblioth√®que externe pour les algos)
- **7 types de corr√©lation** test√©s pour couvrir diff√©rents cas d'usage
- **1029 r√©sultats** de benchmarks sur 85 instances
- **13 tailles diff√©rentes** (n = 4 √† 10,000 items)
- **Analyses statistiques**
- **Guide de d√©cision pratique** pour choisir l'algorithme optimal
- **Code 100% reproductible** avec seeds fix√©es

### Notre Contribution

Au-del√† de l'impl√©mentation technique, nous avons cr√©√© un **guide pratique** montrant **quand et pourquoi** utiliser chaque algorithme. Chaque analyse r√©pond √† une question concr√®te, √©vitant les statistiques complexes sans utilit√©.

---

## Reproduction des R√©sultats

### Reproduction Compl√®te

**Dur√©e estim√©e :** ~30-60 minutes (selon votre machine)

```bash
# 1. Lancer Jupyter Notebook
jupyter notebook knapsack_project.ipynb

# 2. Ex√©cuter les cellules dans l'ordre :
#    - Cellules 1-4 : Imports et structures de donn√©es
#    - Cellules 5-30 : Impl√©mentation des 16 algorithmes
#    - Cellule 42 : G√©n√©ration des benchmarks (OPTIONNEL - d√©j√† fournis)
#    - Cellule 48 : Ex√©cution des benchmarks (~30 min)
#    - Cellules 50-65 : Analyses et visualisations
```

**Attention Note :** L'ex√©cution compl√®te des benchmarks prend du temps.

---

## Installation D√©taill√©e

### Pr√©requis

- **Python 3.8 ou sup√©rieur** (test√© sur 3.8, 3.9, 3.10, 3.11)
- **pip** (gestionnaire de paquets Python)
- **Jupyter Notebook** ou **JupyterLab**
- **8 GB RAM minimum** (16 GB recommand√© pour g√©n√©rer de nouveaux benchmarks)

### V√©rifier votre installation Python

```bash
python --version  # Doit afficher Python 3.8 ou sup√©rieur
pip --version     # Doit afficher pip 20.0 ou sup√©rieur
```

### Installation

```bash
# Biblioth√®ques scientifiques de base
pip install numpy
pip install pandas
pip install scipy

# Visualisation
pip install matplotlib
pip install seaborn

# Machine Learning
pip install scikit-learn

# Jupyter
pip install jupyter
pip install notebook
```

#### 3. V√©rifier l'installation

```python
# Ouvrir Python et tester les imports
python -c "
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import wilcoxon
from sklearn.model_selection import ParameterGrid
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score
print('Toutes les d√©pendances sont install√©es correctement!')
"
```

---

## üìñ Guide d'Utilisation Complet

### √âtape 1 : Comprendre la Structure du Notebook

Le notebook `knapsack_project.ipynb` est organis√© en 8 sections :

```
Section 1 : Configuration et Imports
Section 2 : Structures de Donn√©es (Item, Problem, Solution)
Section 3 : Parsing des Benchmarks
Section 4 : Impl√©mentation des 16 Algorithmes
Section 5 : Syst√®me de Benchmarking
Section 6 : G√©n√©ration d'Instances de Test
Section 7 : Visualisations et Analyses
Section 8 : Optimisation des Hyperparam√®tres (ne fonctionne pas)
```

### √âtape 2 : Ex√©cuter les Algorithmes

#### A. Tester un algorithme sur une instance simple

```python
# Cr√©er une instance manuelle
items = [
    Item(0, weight=10, value=60),
    Item(1, weight=20, value=100),
    Item(2, weight=30, value=120)
]
problem = Problem(items, capacity=50)

# Tester diff√©rents algorithmes
solution_dp = dynamic_programming(problem)
solution_greedy = greedy_ratio(problem)
solution_genetic = genetic_algorithm(problem, seed=42)

# Comparer les r√©sultats
print(f"DP:      valeur={solution_dp.total_value}, temps={solution_dp.time*1000:.2f}ms")
print(f"Greedy:  valeur={solution_greedy.total_value}, temps={solution_greedy.time*1000:.2f}ms")
print(f"Genetic: valeur={solution_genetic.total_value}, temps={solution_genetic.time*1000:.2f}ms")
```

#### B. Charger et tester une instance de benchmark

```python
# Charger une instance depuis un fichier
problem = parse_benchmark_file('benchmarks/generated/uncorrelated_n100_c5000.txt')

print(f"Instance charg√©e: n={problem.n}, capacity={problem.capacity}")

# Tester un algorithme
solution = genetic_algorithm(
    problem,
    population_size=100,
    generations=50,
    mutation_rate=0.02,
    crossover_rate=0.8,
    seed=42
)

print(f"Valeur: {solution.total_value}")
print(f"Poids: {solution.total_weight}/{problem.capacity}")
print(f"Temps: {solution.time * 1000:.2f} ms")
print(f"Items s√©lectionn√©s: {len(solution.selected_items)}")
```

### √âtape 3 : G√©n√©rer de Nouveaux Benchmarks (OPTIONNEL)



### √âtape 4 : Ex√©cuter les Benchmarks Complets

```python
# ATTENTION: Ceci prend ~30-60 minutes
results_df = run_all_benchmarks()

# Les r√©sultats sont automatiquement sauvegard√©s dans:
# - benchmarks/generated
# Des benchmarks avec r√©sultats connus sont aussi pr√©sents dans benchmarks/
```

### √âtape 5 : Analyser les R√©sultats

#### Batch d'instances

### √âtape 5 : Analyser les R√©sultats

#### Batch d'instances

Notre g√©n√©rateur de benchmarks a cr√©√© **66 instances** r√©parties strat√©giquement selon la taille et le type de corr√©lation :
```python
# =============================================================================
# GENERATOR OF BENCHMARK
# =============================================================================
# Types: 'uncorrelated', 'weakly_correlated', 'strongly_correlated'
# =============================================================================

# Instances de taille MOYENNE (n = 100-500)
generate_benchmarks(n=100,  capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=6)
generate_benchmarks(n=200,  capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=2)
generate_benchmarks(n=500,  capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=5)

# Instances de GRANDE taille (n = 1000-5000)
generate_benchmarks(n=1000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=3)
generate_benchmarks(n=2000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=3)
generate_benchmarks(n=5000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=2)

# Instance de TR√àS GRANDE taille (n = 10000)
generate_benchmarks(n=10000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'])

# Exemples comment√©s pour d'autres configurations possibles:
# generate_benchmarks(n=100, capacity=5000, correlation='uncorrelated')
# generate_benchmarks(n=100, capacity=5000, correlation='strongly_correlated', count=5)
# generate_benchmarks(n=100, capacity=5000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'])
# generate_benchmarks(n=100, capacity=5000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=5)
```

#### C. G√©n√©rer les visualisations du notebook

Ex√©cutez simplement les cellules 50-65 du notebook. Elles g√©n√®rent :

- Temps d'√©xecution
- Heatmap de couverture des tests
- Performance par taille
- Compris temps-qualit√©
- R√©gression pr√©dictive
- Comparaisons statistiques
- Optimisation des hyperparam√®tres (ne fonctionne pas correctement voir le rapport)

---

## üìÅ Structure du Projet

```
knapsack_project/
‚îÇ
‚îú‚îÄ‚îÄ knapsack_project.ipynb          # ‚òÖ NOTEBOOK PRINCIPAL ‚òÖ
‚îÇ
‚îî‚îÄ‚îÄ benchmarks/                      # ‚òÖ TES DONN√âES ‚òÖ
    ‚îú‚îÄ‚îÄ generated/                   # Instances g√©n√©r√©es
    ‚îÇ   ‚îú‚îÄ‚îÄ *.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ *.txt
    ‚îÇ   ‚îú‚îÄ‚îÄ *.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ *.txt
    ‚îÇ
    ‚îú‚îÄ‚îÄ large_scale/                 # Instances grandes tailles
    ‚îú‚îÄ‚îÄ large_scale_optimum/         # Solutions optimales large_scale
    ‚îú‚îÄ‚îÄ low_dimension/               # Instances petites tailles
    ‚îî‚îÄ‚îÄ low_dimension_optimum/       # Solutions optimales low_dimension      
```

---

## Algorithmes Impl√©ment√©s

### 1. Algorithmes Exacts (Optimalit√© Garantie)

| Algorithme | Complexit√© Temps | Complexit√© Espace | Limite Pratique | Impl√©mentation |
|------------|------------------|-------------------|-----------------|----------------|
| **Brute Force** | O(2^n) | O(n) | n ‚â§ 23 | Cellule 6 |
| **Dynamic Programming** | O(n√óC) | O(n√óC) | n ‚â§ 5000, C petit | Cellule 7 |
| **DP Top-Down** | O(n√óC) | O(n√óC) | n ‚â§ 5000 | Cellule 8 |
| **Branch and Bound** | O(2^n) ~ O(n log n) | O(n) | n ‚â§ 500 (variable) | Cellule 9 |

**Quand utiliser :**
- Brute Force : Petites instances (n ‚â§ 20), v√©rification
- DP : Instances moyennes (n ‚â§ 1000) avec capacit√© mod√©r√©e
- B&B : Probl√®mes avec bonne borne sup√©rieure

---

### 2. Algorithmes d'Approximation (Garantie Th√©orique)

| Algorithme | Complexit√© | Garantie | Impl√©mentation |
|------------|------------|----------|----------------|
| **FPTAS (Œµ=0.1)** | O(n¬≤/Œµ) | ‚â• (1-Œµ)√óOPT | Cellule 18 |
| **FPTAS (Œµ=0.05)** | O(n¬≤/Œµ) | ‚â• (1-Œµ)√óOPT | Cellule 18 |
| **FPTAS Adaptive** | O(n¬≤/Œµ) | ‚â• (1-Œµ)√óOPT | Cellule 19 |

** Attention Limitation connue :** Notre impl√©mentation FPTAS a un bug de scaling qui limite n ‚â§ 100. Voir section [Probl√®mes Connus](#probl√®mes-connus-et-limitations).

**Quand utiliser :**
- Besoin de garantie th√©orique
- Instances moyennes (n ‚â§ 500 apr√®s correction)
- Compromis qualit√©/temps ajustable via Œµ

---

### 3. Heuristiques Gloutonnes (Ultra-Rapides)

| Algorithme | Tri Par | Complexit√© | Performance | Impl√©mentation |
|------------|---------|------------|-------------|----------------|
| **Greedy Ratio** | value/weight ‚Üì | O(n log n) | 70-100% selon type | Cellule 10 |
| **Greedy Value** | value ‚Üì | O(n log n) | 60-95% | Cellule 11 |
| **Greedy Weight** | weight ‚Üë | O(n log n) | 50-90% | Cellule 12 |
| **Fractional** | ratio ‚Üì | O(n log n) | Borne sup√©rieure | Cellule 13 |

**Quand utiliser :**
- Contrainte temps stricte (< 1 ms)
- Greedy Ratio : strongly_correlated (quasi-optimal)
- Greedy Value : uncorrelated, inverse_strongly
- Greedy Weight : √âviter sur inverse_strongly (tr√®s mauvais)

---

### 4. M√©taheuristiques (Grandes Instances)

| Algorithme | Param√®tres Cl√©s | Temps | Performance | Impl√©mentation |
|------------|-----------------|-------|-------------|----------------|
| **Genetic Algorithm** | pop=100, gen=50 | 100-500 ms | 85-98% | Cellule 14 |
| **Genetic Adaptive** | Adaptatifs | 100-500 ms | 87-99% (+ stable) | Cellule 15 |
| **Simulated Annealing** | T=1000, Œ±=0.995 | 50-200 ms | 85-97% | Cellule 16 |
| **SA Adaptive** | Adaptatifs | 50-200 ms | 88-98% (+ stable) | Cellule 17 |
| **Randomized** | Glouton + al√©a | 5-20 ms | 70-90% | Cellule 20 |

**Quand utiliser :**
- Grandes instances (n > 1000)
- Temps flexible (quelques secondes OK)
- Besoin de stabilit√© ‚Üí versions Adaptive

---

## Donn√©es et Benchmarks

### Format des Fichiers de Benchmark

Nos fichiers `.txt` suivent ce format standard :

```
100 5000
# n capacity
# Puis n lignes avec : value weight
60 10
100 20
120 30
...
```

### Types de Corr√©lation G√©n√©r√©s

Nous avons g√©n√©r√© **4 types diff√©rents** pour tester les algorithmes dans divers contextes :

#### 1. **Uncorrelated** (Non-corr√©l√©)
```python
weights = random(1, 100)
values = random(1, 100)  # Ind√©pendants
```
**Usage :** Cas g√©n√©ral, pas de structure particuli√®re

---

#### 2. **Strongly Correlated** (Fortement corr√©l√©)
```python
weights = random(1, 100)
values = weights  # Exactement √©gaux
```
**Usage :** Teste si Greedy Ratio trouve l'optimal (devrait !)

---

#### 3. **Weakly Correlated** (Faiblement corr√©l√©)
```python
weights = random(1, 100)
values = weights + noise(-15, 15)  # Proche mais avec bruit
```
**Usage :** Teste robustesse au bruit

---

#### 4. **Similar Weights** (Poids similaires)
```python
weights = random(47, 53)  # Tous proches de 50
values = random(1, 100)   # Valeurs vari√©es
```
**Usage :** Force Greedy Weight √† √™tre m√©diocre

---


##  R√©sultats et Analyses

### Analyse 1 : Taux de Solutions Optimales

**Question :** Quel algorithme trouve l'optimal le plus souvent ?

| Algorithme | % Optimal | Gap Moyen | Verdict |
|------------|-----------|-----------|---------|
| Dynamic Programming | 100.0% | 0.00% | ‚úì OPTIMAL |
| DP Top-Down | 100.0% | 0.00% | ‚úì OPTIMAL |
| Branch and Bound | 100.0% | 0.00% | ‚úì OPTIMAL |
| FPTAS (Œµ=0.05) | 99.2% | 0.15% | ~ QUASI-OPTIMAL |
| FPTAS (Œµ=0.1) | 95.8% | 0.31% | ~ QUASI-OPTIMAL |
| Greedy Ratio | 78.5% | 2.34% | ‚óã BON |
| Genetic Adaptive | 12.3% | 4.21% | ‚óã APPROX |
| Simulated Annealing | 8.7% | 5.12% | ‚óã APPROX |

---

### Analyse 2 : Limites de Praticabilit√© (< 5 secondes)

**Question :** Jusqu'√† quelle taille puis-je utiliser chaque algorithme ?

| Algorithme | Taille Max (n) | Temps √† Max | Complexit√© Confirm√©e |
|------------|----------------|-------------|----------------------|
| Brute Force | 23 | 4.8s | ‚úì O(2^n) |
| Branch and Bound | 500 | Variable | ‚úì √âlagage d√©pendant |
| Dynamic Programming | 5000 | D√©pend C | ‚úì O(n√óC) |
| FPTAS | 100 | 2.2s (BUG) | ‚úó Devrait √™tre plus |
| Gloutons | 10000+ | < 1s | ‚úì O(n log n) |
| M√©taheuristiques | 10000+ | Ajustable | ‚úì Scalable |

---

### Analyse 3 : Performance des Gloutons par Type

**Question :** Quel glouton choisir selon le type de probl√®me ?

**R√©sultats :**

| Type de Corr√©lation | Meilleur Glouton | Gap | Pire Glouton | Gap |
|---------------------|------------------|-----|--------------|-----|
| **Strongly Correlated** | Greedy Ratio | 0.12% ‚úì | Greedy Weight | 8.45% |
| **Uncorrelated** | Greedy Value | 3.78% | Greedy Weight | 9.21% |
| **Weakly Correlated** | Greedy Ratio | 1.89% | Greedy Weight | 7.56% |
| **Similar Weights** | Greedy Value/Ratio | 4.12% | Greedy Weight | 12.34% |

** Remarques:**
- Greedy Ratio **quasi-optimal** sur strongly_correlated (0.12% gap)
- Le **crit√®re de tri** est crucial selon la structure des donn√©es

---

### Analyse 4 : Arbre de D√©cision Pratique

**Question :** Quel algorithme choisir dans mon contexte ?

```
‚îå‚îÄ Besoin d'OPTIMALIT√â GARANTIE ?
‚îÇ
‚îú‚îÄ OUI ‚Üí Ai-je n√óC < 10 millions ?
‚îÇ        ‚îÇ
‚îÇ        ‚îú‚îÄ OUI ‚Üí DYNAMIC PROGRAMMING
‚îÇ        ‚îÇ        ‚úì Optimal garanti
‚îÇ        ‚îÇ        ‚úì O(n√óC) pr√©visible
‚îÇ        ‚îÇ        ‚úó Limit√© par m√©moire
‚îÇ        ‚îÇ
‚îÇ        ‚îî‚îÄ NON ‚Üí BRANCH AND BOUND
‚îÇ                 ‚úì Optimal garanti
‚îÇ                 ~ Temps variable (√©lagage)
‚îÇ                 ‚úó Peut √™tre lent
‚îÇ
‚îî‚îÄ NON ‚Üí Quelle est ma CONTRAINTE principale ?
         ‚îÇ
         ‚îú‚îÄ TEMPS STRICT (<1ms)
         ‚îÇ  ‚îÇ
         ‚îÇ  ‚îî‚îÄ Quel TYPE de probl√®me ?
         ‚îÇ     ‚îú‚îÄ strongly_correlated ‚Üí GREEDY RATIO ‚úì Quasi-optimal
         ‚îÇ     ‚îú‚îÄ uncorrelated ‚Üí GREEDY VALUE
         ‚îÇ     ‚îú
         ‚îÇ     ‚îî‚îÄ autre ‚Üí GREEDY RATIO (par d√©faut)
         ‚îÇ
         ‚îú‚îÄ QUALIT√â IMPORTANTE (quelques secondes OK)
         ‚îÇ  ‚îÇ
         ‚îÇ  ‚îú‚îÄ n < 200 ‚Üí FPTAS (Œµ=0.05)
         ‚îÇ  ‚îÇ            ‚úì Garantie (1-Œµ)√óOPT
         ‚îÇ  ‚îÇ            ‚úì Temps polynomial
         ‚îÇ  ‚îÇ
         ‚îÇ  ‚îî‚îÄ n ‚â• 200 ‚Üí M√âTAHEURISTIQUE
         ‚îÇ               ‚îú‚îÄ Besoin STABILIT√â ‚Üí Genetic/SA Adaptive
         ‚îÇ               ‚îî‚îÄ Performance max ‚Üí Genetic Algorithm
         ‚îÇ
         ‚îî‚îÄ GRANDE INSTANCE (n > 1000)
            ‚îÇ
            ‚îî‚îÄ SIMULATED ANNEALING ou GENETIC ALGORITHM
               ‚úì Seuls √† passer l'√©chelle
               ~ Temps ajustable
               ~ Qualit√© non garantie mais bonne (85-98%)
```

**Tableau r√©capitulatif :**

| Crit√®re | DP | B&B | Greedy | FPTAS | Genetic | SA |
|---------|----|----|--------|-------|---------|-----|
| Optimal | ‚úì | ‚úì | ‚úó | ~ | ‚úó | ‚úó |
| Rapide (<1ms) | ‚úó | ‚úó | ‚úì | ‚úó | ‚úó | ‚úó |
| Scalable (n>1000) | ‚úó | ‚úó | ‚úì | ~ | ‚úì | ‚úì |
| Stable | ‚úì | ‚úì | ‚úì | ‚úì | ~ | ~ |
| M√©moire OK | ‚úó | ‚úì | ‚úì | ~ | ‚úì | ‚úì |

---

## Probl√®mes Connus

### FPTAS - Dysfonctionnement au-del√† de n=100

**Sympt√¥mes observ√©s :**
- FPTAS ne fonctionne pas pour n > 100
- Temps d'ex√©cution anormalement √©lev√©s :
  - n=100, Œµ=0.05 : 2222 ms (vs 21 ms pour DP)
  - n=100, Œµ=0.1 : 1087 ms (vs 21 ms pour DP)
- Ratio: FPTAS est 100√ó plus lent que DP alors qu'il devrait √™tre comparable !

**Cause identifi√©e :**

L'erreur provient de la formule de scaling dans la cellule 18 :

```python
# NOTRE CODE (INCORRECT):
K = (epsilon * v_max) / n

# Exemple: n=200, v_max=1000, Œµ=0.1
# K = (0.1 √ó 1000) / 200 = 0.5  ‚Üê K trop petit!

# R√©sultat:
# scaled_value = floor(500 / 0.5) = 1000  ‚Üê 2x plus grand!
# V_scaled = Œ£ scaled_values ‚âà 200,000   ‚Üê Explosion!
# Tableau DP: n √ó V_scaled = 200 √ó 200,000 = 40M cellules
```

**Solution propos√©e :**

```python
# FORMULE CORRECTE:
K = max(1, (epsilon * v_max) / (2 * n))

# Ou ajuster epsilon pour grandes instances:
if n > 100:
    epsilon_adjusted = epsilon * (n / 100)
    K = max(1, (epsilon_adjusted * v_max) / n)
```

**Impact sur les r√©sultats :**
- Heatmap de couverture : cellules FPTAS vides pour n > 100
- Graphiques de performance : FPTAS absents des grandes tailles

**Statut : **Identifi√© et document√©** dans le rapport (section 5.5). Non corrig√© dans le code pour pr√©server l'authenticit√© des r√©sultats pr√©sent√©s.

---


**"Il n'y a pas de meilleur algorithme universel - le contexte d√©termine le choix optimal."**
