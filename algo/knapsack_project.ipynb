{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knapsack Problem 0-1 Project\n",
    "\n",
    "**Team:** Chaabane, Arman, Bartosz, Ahmed\n",
    "\n",
    "## Project Structure\n",
    "\n",
    "1. Common Infrastructure (Classes and data structures)\n",
    "2. Implemented Algorithms\n",
    "3. Complete Benchmarking System\n",
    "4. In-depth Comparative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from typing import Literal, Optional, Tuple, List\n",
    "from dataclasses import dataclass\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from types import SimpleNamespace\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "ALGO_COLORS = {\n",
    "    'Brute Force': '#e41a1c',\n",
    "    'Dynamic Programming': '#377eb8',\n",
    "    'DP Top-Down': '#4daf4a',\n",
    "    'Branch and Bound': '#984ea3',\n",
    "    'Greedy Ratio': '#ff7f00', \n",
    "    'Greedy Value': '#ffff33', \n",
    "    'Greedy Weight': '#a65628', \n",
    "    'Fractional Knapsack': '#f781bf',\n",
    "    'Randomized': '#999999', \n",
    "    'Genetic Algorithm': '#17becf',  \n",
    "    'Genetic Adaptive': '#1f77b4',      \n",
    "    'Simulated Annealing': '#d62728',   \n",
    "    'SA Adaptive': '#ff9896',          \n",
    "    'FTPAS (ε=0.1)': '#9467bd',         \n",
    "    'FTPAS (ε=0.05)': '#8c564b',        \n",
    "    'FTPAS Adaptive': '#e377c2',        \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knapsack Benchmark Generator\n",
    "\n",
    "This generator allows creating custom benchmark files with different parameters:\n",
    "- **Correlation type**: uncorrelated, weakly_correlated, strongly_correlated, similar_weights\n",
    "- **Number of items (n)**: number of objects in the instance\n",
    "- **Weight range (R)**: maximum value for randomly generated weights\n",
    "- **Capacity**: can be specified or calculated automatically (usually 50% of the sum of weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_DIR = \"benchmarks/generated\"\n",
    "\n",
    "@dataclass\n",
    "class KnapsackInstance:\n",
    "    n: int\n",
    "    capacity: int\n",
    "    weights: List[int]\n",
    "    values: List[int]\n",
    "    correlation_type: str\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"KnapsackInstance(n={self.n}, capacity={self.capacity}, type={self.correlation_type})\"\n",
    "\n",
    "\n",
    "class KnapsackBenchmarkGenerator:\n",
    "    CORRELATION_TYPES = [\n",
    "        'uncorrelated',\n",
    "        'weakly_correlated', \n",
    "        'strongly_correlated'\n",
    "    ]\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.rng = np.random.default_rng()\n",
    "    \n",
    "    def generate(self, n: int, R: int = 1000, capacity: Optional[int] = None,\n",
    "                 capacity_ratio: float = 0.5, correlation_type: str = 'uncorrelated',\n",
    "                 correlation_param: float = 100.0) -> KnapsackInstance:\n",
    "        if correlation_type not in self.CORRELATION_TYPES:\n",
    "            raise ValueError(f\"Unknown type: {correlation_type}. Options: {self.CORRELATION_TYPES}\")\n",
    "        \n",
    "        weights = self._generate_weights(n, R, correlation_type, correlation_param)\n",
    "        values = self._generate_values(weights, R, correlation_type, correlation_param)\n",
    "        \n",
    "        if capacity is None:\n",
    "            capacity = int(capacity_ratio * sum(weights))\n",
    "        capacity = max(1, capacity)\n",
    "        \n",
    "        return KnapsackInstance(n=n, capacity=capacity, weights=weights.tolist(), \n",
    "                                values=values.tolist(), correlation_type=correlation_type)\n",
    "    \n",
    "    def _generate_weights(self, n: int, R: int, correlation_type: str, correlation_param: float) -> np.ndarray:\n",
    "        weights = self.rng.integers(1, R + 1, n)\n",
    "        return weights.astype(int)\n",
    "    \n",
    "    def _generate_values(self, weights: np.ndarray, R: int, correlation_type: str, correlation_param: float) -> np.ndarray:\n",
    "        n = len(weights)\n",
    "        if correlation_type == 'uncorrelated':\n",
    "            values = self.rng.integers(1, R + 1, n)\n",
    "        elif correlation_type == 'weakly_correlated':\n",
    "            noise = self.rng.integers(-int(correlation_param), int(correlation_param) + 1, n)\n",
    "            values = np.maximum(weights + noise, 1)\n",
    "        elif correlation_type == 'strongly_correlated':\n",
    "            values = weights + int(correlation_param)\n",
    "        return values.astype(int)\n",
    "    \n",
    "    def _build_filename(self, instance: KnapsackInstance, index: int = None, format: str = 'standard') -> str:\n",
    "        ext = '.kp' if format == 'kp' else '.txt'\n",
    "        base = f\"{instance.correlation_type}_n{instance.n}_c{instance.capacity}\"\n",
    "        if index is not None:\n",
    "            return f\"{base}_{index:03d}{ext}\"\n",
    "        return f\"{base}{ext}\"\n",
    "    \n",
    "    def save_to_file(self, instance: KnapsackInstance, filepath: str = None,\n",
    "                     index: int = None, format: Literal['standard', 'kp'] = 'standard') -> str:\n",
    "        if filepath is None:\n",
    "            filepath = os.path.join(GENERATED_DIR, self._build_filename(instance, index, format))\n",
    "        \n",
    "        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)\n",
    "        with open(filepath, 'w') as f:\n",
    "            if format == 'standard':\n",
    "                f.write(f\"{instance.n} {instance.capacity}\\n\")\n",
    "                for v, w in zip(instance.values, instance.weights):\n",
    "                    f.write(f\"{v} {w}\\n\")\n",
    "            elif format == 'kp':\n",
    "                f.write(f\"\\n{instance.n}\\n{instance.capacity}\\n\\n\")\n",
    "                for v, w in zip(instance.values, instance.weights):\n",
    "                    f.write(f\"{v} {w}\\n\")\n",
    "        return filepath\n",
    "\n",
    "\n",
    "def generate_benchmarks(n: int, capacity: int = None, correlation = 'uncorrelated',\n",
    "                        R: int = 1000, count: int = 1, format: str = 'standard') -> List[KnapsackInstance]:\n",
    "    \"\"\"\n",
    "    Generates one or more benchmark files.\n",
    "    \n",
    "    Args:\n",
    "        n: Number of items\n",
    "        capacity: Knapsack capacity (None = 50% of sum of weights)\n",
    "        correlation: Type or list of types ('uncorrelated', 'weakly_correlated', 'strongly_correlated')\n",
    "        R: Max weight [1, R]\n",
    "        count: Number of files to generate per type\n",
    "        format: 'standard' (.txt) or 'kp'\n",
    "    \"\"\"\n",
    "    generator = KnapsackBenchmarkGenerator()\n",
    "    instances = []\n",
    "    \n",
    "    correlations = [correlation] if isinstance(correlation, str) else correlation\n",
    "    \n",
    "    for corr_type in correlations:\n",
    "        for i in range(count):\n",
    "            instance = generator.generate(n=n, R=R, capacity=capacity, correlation_type=corr_type)\n",
    "            index = i + 1 if count > 1 else None\n",
    "            filepath = generator.save_to_file(instance, index=index, format=format)\n",
    "            instances.append(instance)\n",
    "    \n",
    "    return instances\n",
    "\n",
    "\n",
    "print(f\"Folder: {GENERATED_DIR}\")\n",
    "print(f\"Types: {KnapsackBenchmarkGenerator.CORRELATION_TYPES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# GENERATOR OF BENCHMARK\n",
    "# =============================================================================\n",
    "# Types: 'uncorrelated', 'weakly_correlated', 'strongly_correlated'\n",
    "# =============================================================================\n",
    "generate_benchmarks(n=100, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=6)\n",
    "generate_benchmarks(n=200, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=2)\n",
    "generate_benchmarks(n=500, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=5)\n",
    "generate_benchmarks(n=1000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=3)\n",
    "generate_benchmarks(n=2000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=3)\n",
    "generate_benchmarks(n=5000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=2)\n",
    "generate_benchmarks(n=10000, capacity=1000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# generate_benchmarks(n=100, capacity=5000, correlation='uncorrelated')\n",
    "# generate_benchmarks(n=100, capacity=5000, correlation='strongly_correlated', count=5)\n",
    "# generate_benchmarks(n=100, capacity=5000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'])\n",
    "# generate_benchmarks(n=100, capacity=5000, correlation=['uncorrelated', 'strongly_correlated', 'weakly_correlated'], count=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Common Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Item:\n",
    "    \"\"\"Represents an item with its weight and value\"\"\"\n",
    "    def __init__(self, item_id, weight, value):\n",
    "        self.id = item_id\n",
    "        self.weight = weight\n",
    "        self.value = value\n",
    "    \n",
    "    def ratio(self):\n",
    "        return self.value / self.weight if self.weight > 0 else 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Item({self.id}, w={self.weight}, v={self.value})\"\n",
    "\n",
    "\n",
    "class Problem:\n",
    "    \"\"\"Represents a knapsack problem instance\"\"\"\n",
    "    def __init__(self, items, capacity):\n",
    "        self.items = items\n",
    "        self.capacity = capacity\n",
    "        self.n = len(items)\n",
    "\n",
    "\n",
    "class Solution:\n",
    "    \"\"\"Represents a solution to the problem\"\"\"\n",
    "    def __init__(self, selected_items, total_value, total_weight, time_taken):\n",
    "        self.selected_items = selected_items\n",
    "        self.total_value = total_value\n",
    "        self.total_weight = total_weight\n",
    "        self.time = time_taken\n",
    "        self.usage_percent = (total_weight / 1.0) * 100  # Will be updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brute_force(problem):\n",
    "    \"\"\"\n",
    "    Brute force algorithm for the 0-1 Knapsack problem\n",
    "    \n",
    "    Explores all possible combinations of items to find\n",
    "    the optimal solution. Guarantees optimal solution but with\n",
    "    exponential complexity.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object with the optimal solution\n",
    "    \n",
    "    Note:\n",
    "        Do not use for n > 20-25 items (prohibitive time)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    best_value = 0\n",
    "    best_weight = 0\n",
    "    best_items = []\n",
    "    \n",
    "    for size in range(problem.n + 1):\n",
    "        for combo in combinations(range(problem.n), size):\n",
    "            total_weight = sum(problem.items[i].weight for i in combo)\n",
    "            total_value = sum(problem.items[i].value for i in combo)\n",
    "            \n",
    "            if total_weight <= problem.capacity and total_value > best_value:\n",
    "                best_value = total_value\n",
    "                best_weight = total_weight\n",
    "                best_items = list(combo)\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    sol = Solution(best_items, best_value, best_weight, time_taken)\n",
    "    sol.usage_percent = (best_weight / problem.capacity) * 100 if problem.capacity > 0 else 0\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_programming(problem):\n",
    "    \"\"\"\n",
    "    Bottom-Up Dynamic Programming for the 0-1 Knapsack problem\n",
    "    \n",
    "    Builds a memoization table iteratively starting from\n",
    "    the simplest sub-problems to the complete problem.\n",
    "    Guarantees optimal solution in pseudo-polynomial time.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object with optimal solution, or None if\n",
    "        matrix is too large (memory protection)\n",
    "    \n",
    "    Note:\n",
    "        Memory limited for large capacities (> 10M cells)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    n = problem.n\n",
    "    C = problem.capacity\n",
    "    \n",
    "    total_cells = n * C\n",
    "    if total_cells > 10_000_000:\n",
    "        print(f\"DP Skip: matrix too large ({n}×{C:,} = {total_cells:,})\")\n",
    "        return None\n",
    "    \n",
    "    estimated_mb = (total_cells * 8) / (1024 * 1024)\n",
    "    if estimated_mb > 500:\n",
    "        print(f\"DP Skip: memory > 500 MB ({estimated_mb:.0f} MB)\")\n",
    "        return None\n",
    "    \n",
    "    dp = [[0 for _ in range(C + 1)] for _ in range(n + 1)]\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        item = problem.items[i - 1]\n",
    "        for w in range(C + 1):\n",
    "            dp[i][w] = dp[i - 1][w]\n",
    "            if item.weight <= w:\n",
    "                dp[i][w] = max(dp[i][w], dp[i - 1][w - item.weight] + item.value)\n",
    "    \n",
    "    # Reconstruction\n",
    "    selected = []\n",
    "    w = C\n",
    "    for i in range(n, 0, -1):\n",
    "        if dp[i][w] != dp[i - 1][w]:\n",
    "            selected.append(i - 1)\n",
    "            w -= problem.items[i - 1].weight\n",
    "    \n",
    "    total_value = dp[n][C]\n",
    "    total_weight = sum(problem.items[i].weight for i in selected)\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    sol = Solution(selected, total_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / problem.capacity) * 100 if problem.capacity > 0 else 0\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Dynamic Programming Top-Down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_programming_topdown(problem):\n",
    "    \"\"\"\n",
    "    Top-Down Dynamic Programming with memoization\n",
    "    \n",
    "    Advantages over Bottom-Up:\n",
    "    - Only computes necessary sub-problems\n",
    "    - More intuitive (follows recursive definition)\n",
    "    - Can be faster if not all sub-problems are needed\n",
    "    \n",
    "    Returns:\n",
    "        Solution object\n",
    "    \"\"\"\n",
    "    import sys\n",
    "    start_time = time.time()\n",
    "    \n",
    "    n = problem.n\n",
    "    C = problem.capacity\n",
    "    items = problem.items\n",
    "    \n",
    "    # Protection against large instances\n",
    "    total_cells = n * C\n",
    "    if total_cells > 10_000_000:\n",
    "        print(f\"DP Top-Down Skip: matrix too large ({n}×{C:,} = {total_cells:,})\")\n",
    "        return None\n",
    "    \n",
    "    # Increase recursion limit if necessary\n",
    "    old_limit = sys.getrecursionlimit()\n",
    "    if n > old_limit - 100:\n",
    "        sys.setrecursionlimit(n + 1000)\n",
    "    \n",
    "    # Cache for memoization: memo[i][w] = max value with items 0..i-1 and capacity w\n",
    "    memo = {}\n",
    "    \n",
    "    def knapsack(i, w):\n",
    "        \"\"\"Recursive function with memoization\"\"\"\n",
    "        # Base case\n",
    "        if i == 0 or w == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Check cache\n",
    "        if (i, w) in memo:\n",
    "            return memo[(i, w)]\n",
    "        \n",
    "        item = items[i - 1]\n",
    "        \n",
    "        # If item is too heavy, we cannot take it\n",
    "        if item.weight > w:\n",
    "            result = knapsack(i - 1, w)\n",
    "        else:\n",
    "            # Max between taking and not taking the item\n",
    "            result = max(\n",
    "                knapsack(i - 1, w),  # Don't take\n",
    "                knapsack(i - 1, w - item.weight) + item.value  # Take\n",
    "            )\n",
    "        \n",
    "        memo[(i, w)] = result\n",
    "        return result\n",
    "    \n",
    "    # Compute optimal value\n",
    "    optimal_value = knapsack(n, C)\n",
    "    \n",
    "    if optimal_value == 0:\n",
    "        time_taken = time.time() - start_time\n",
    "        return Solution([], 0, 0, time_taken)\n",
    "    \n",
    "    # Solution reconstruction\n",
    "    selected = []\n",
    "    w = C\n",
    "    for i in range(n, 0, -1):\n",
    "        # If value changes when excluding this item, it means we took it\n",
    "        if knapsack(i, w) != knapsack(i - 1, w):\n",
    "            selected.append(i - 1)\n",
    "            w -= items[i - 1].weight\n",
    "    \n",
    "    total_weight = sum(items[i].weight for i in selected)\n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    # Restore recursion limit\n",
    "    sys.setrecursionlimit(old_limit)\n",
    "    \n",
    "    sol = Solution(selected, optimal_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / C) * 100 if C > 0 else 0\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Branch and Bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branch_and_bound(problem):\n",
    "    \"\"\"\n",
    "    Branch and Bound algorithm for the 0-1 Knapsack problem\n",
    "    \n",
    "    Intelligently explores the solution tree using\n",
    "    an upper bound (fractional relaxation) to prune\n",
    "    unpromising branches. Guarantees optimal solution.\n",
    "    \n",
    "    Strategy:\n",
    "    - Sort items by decreasing value/weight ratio\n",
    "    - Calculate upper bound via fractional relaxation\n",
    "    - Prune branches where bound < best known solution\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object with optimal solution\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sorted_indices = sorted(range(problem.n), \n",
    "                          key=lambda i: problem.items[i].ratio(), \n",
    "                          reverse=True)\n",
    "    \n",
    "    best_value = 0\n",
    "    best_solution = []\n",
    "    \n",
    "    def bound(level, current_weight, current_value):\n",
    "        if current_weight >= problem.capacity:\n",
    "            return 0\n",
    "        \n",
    "        value_bound = current_value\n",
    "        total_weight = current_weight\n",
    "        \n",
    "        for i in range(level, problem.n):\n",
    "            idx = sorted_indices[i]\n",
    "            item = problem.items[idx]\n",
    "            \n",
    "            if total_weight + item.weight <= problem.capacity:\n",
    "                total_weight += item.weight\n",
    "                value_bound += item.value\n",
    "            else:\n",
    "                remaining = problem.capacity - total_weight\n",
    "                value_bound += item.value * (remaining / item.weight)\n",
    "                break\n",
    "        \n",
    "        return value_bound\n",
    "    \n",
    "    def branch(level, current_weight, current_value, current_items):\n",
    "        nonlocal best_value, best_solution\n",
    "        \n",
    "        if level == problem.n:\n",
    "            if current_value > best_value:\n",
    "                best_value = current_value\n",
    "                best_solution = current_items[:]\n",
    "            return\n",
    "        \n",
    "        idx = sorted_indices[level]\n",
    "        item = problem.items[idx]\n",
    "        \n",
    "        if current_weight + item.weight <= problem.capacity:\n",
    "            new_value = current_value + item.value\n",
    "            if bound(level + 1, current_weight + item.weight, new_value) > best_value:\n",
    "                current_items.append(idx)\n",
    "                branch(level + 1, current_weight + item.weight, new_value, current_items)\n",
    "                current_items.pop()\n",
    "        \n",
    "        if bound(level + 1, current_weight, current_value) > best_value:\n",
    "            branch(level + 1, current_weight, current_value, current_items)\n",
    "    \n",
    "    branch(0, 0, 0, [])\n",
    "    \n",
    "    total_weight = sum(problem.items[i].weight for i in best_solution)\n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    sol = Solution(best_solution, best_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / problem.capacity) * 100 if problem.capacity > 0 else 0\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Greedy Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_by_value(problem):\n",
    "    \"\"\"\n",
    "    Greedy algorithm by decreasing value\n",
    "    \n",
    "    Selects items in order of decreasing value\n",
    "    as long as capacity allows. Simple but non-optimal.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object (potentially sub-optimal)\n",
    "    \n",
    "    Note:\n",
    "        Favors high-value items, may ignore\n",
    "        more profitable combinations of cheaper items\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sorted_items = sorted(enumerate(problem.items), key=lambda x: x[1].value, reverse=True)\n",
    "    \n",
    "    selected = []\n",
    "    total_weight = 0\n",
    "    total_value = 0\n",
    "    \n",
    "    for idx, item in sorted_items:\n",
    "        if total_weight + item.weight <= problem.capacity:\n",
    "            selected.append(idx)\n",
    "            total_weight += item.weight\n",
    "            total_value += item.value\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    sol = Solution(selected, total_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / problem.capacity) * 100 if problem.capacity > 0 else 0\n",
    "    return sol\n",
    "\n",
    "\n",
    "def greedy_by_weight(problem):\n",
    "    \"\"\"\n",
    "    Greedy algorithm by increasing weight\n",
    "    \n",
    "    Selects items in order of increasing weight\n",
    "    as long as capacity allows. Maximizes number of items.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object (potentially sub-optimal)\n",
    "    \n",
    "    Note:\n",
    "        Favors small items, may ignore heavy\n",
    "        but very valuable items\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sorted_items = sorted(enumerate(problem.items), key=lambda x: x[1].weight)\n",
    "    \n",
    "    selected = []\n",
    "    total_weight = 0\n",
    "    total_value = 0\n",
    "    \n",
    "    for idx, item in sorted_items:\n",
    "        if total_weight + item.weight <= problem.capacity:\n",
    "            selected.append(idx)\n",
    "            total_weight += item.weight\n",
    "            total_value += item.value\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    sol = Solution(selected, total_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / problem.capacity) * 100 if problem.capacity > 0 else 0\n",
    "    return sol\n",
    "\n",
    "\n",
    "def greedy_by_ratio(problem):\n",
    "    \"\"\"\n",
    "    Greedy algorithm by decreasing value/weight ratio\n",
    "    \n",
    "    Selects items in order of decreasing density (value/weight).\n",
    "    The best greedy heuristic for 0-1.\n",
    "    \n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object (potentially sub-optimal but \n",
    "        often close to optimal)\n",
    "    \n",
    "    Note:\n",
    "        Optimal strategy for fractional knapsack,\n",
    "        good heuristic for 0-1\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sorted_items = sorted(enumerate(problem.items), key=lambda x: x[1].ratio(), reverse=True)\n",
    "    \n",
    "    selected = []\n",
    "    total_weight = 0\n",
    "    total_value = 0\n",
    "    \n",
    "    for idx, item in sorted_items:\n",
    "        if total_weight + item.weight <= problem.capacity:\n",
    "            selected.append(idx)\n",
    "            total_weight += item.weight\n",
    "            total_value += item.value\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    sol = Solution(selected, total_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / problem.capacity) * 100 if problem.capacity > 0 else 0\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.1 Fractional Knapsack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fractional_knapsack(problem):\n",
    "    \"\"\"\n",
    "    Fractional Knapsack - Optimal greedy algorithm for fractional knapsack\n",
    "    \n",
    "    Difference with 0-1 Knapsack:\n",
    "    - Allows taking a FRACTION of an item\n",
    "    - Optimal solution guaranteed (unlike 0-1)\n",
    "    - Serves as upper bound for 0-1 Knapsack\n",
    "    \n",
    "    Strategy: Sort by decreasing value/weight ratio and take \n",
    "    items in that order (fractions if necessary)\n",
    "    \n",
    "    Returns:\n",
    "        Solution object with fraction_taken indicating fractions taken\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    n = problem.n\n",
    "    capacity = problem.capacity\n",
    "    items = problem.items\n",
    "    \n",
    "    # Sort items by decreasing value/weight ratio\n",
    "    sorted_items = sorted(enumerate(items), key=lambda x: x[1].ratio(), reverse=True)\n",
    "    \n",
    "    total_value = 0.0\n",
    "    total_weight = 0.0\n",
    "    selected = []  # List of tuples (index, fraction_taken)\n",
    "    fractions = {}  # To store fractions of each item\n",
    "    \n",
    "    remaining_capacity = capacity\n",
    "    \n",
    "    for idx, item in sorted_items:\n",
    "        if remaining_capacity <= 0:\n",
    "            break\n",
    "            \n",
    "        if item.weight <= remaining_capacity:\n",
    "            # Take whole item\n",
    "            selected.append(idx)\n",
    "            fractions[idx] = 1.0\n",
    "            total_value += item.value\n",
    "            total_weight += item.weight\n",
    "            remaining_capacity -= item.weight\n",
    "        else:\n",
    "            # Take fraction of item\n",
    "            fraction = remaining_capacity / item.weight\n",
    "            fractions[idx] = fraction\n",
    "            total_value += item.value * fraction\n",
    "            total_weight += item.weight * fraction\n",
    "            selected.append(idx)\n",
    "            remaining_capacity = 0\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    # Create solution\n",
    "    # Note: total_value can be a float, we keep it for precision\n",
    "    sol = Solution(selected, total_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / capacity) * 100 if capacity > 0 else 0\n",
    "    sol.fractions = fractions  # Store fractions for reference\n",
    "    sol.is_fractional = True  # Mark as fractional solution\n",
    "    \n",
    "    return sol\n",
    "\n",
    "\n",
    "def fractional_knapsack_bound(problem):\n",
    "    \"\"\"\n",
    "    Calculates upper bound of 0-1 problem via fractional relaxation\n",
    "    \n",
    "    Solves fractional knapsack problem to obtain an upper\n",
    "    bound on the optimal value of the 0-1 problem. Used as\n",
    "    bounding function in Branch and Bound.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        float: Maximum possible value (upper bound for 0-1)\n",
    "    \n",
    "    Note:\n",
    "        This value is always ≥ to the optimum of 0-1 Knapsack\n",
    "    \"\"\"\n",
    "    sorted_items = sorted(problem.items, key=lambda x: x.ratio(), reverse=True)\n",
    "    \n",
    "    total_value = 0.0\n",
    "    remaining_capacity = problem.capacity\n",
    "    \n",
    "    for item in sorted_items:\n",
    "        if remaining_capacity <= 0:\n",
    "            break\n",
    "        if item.weight <= remaining_capacity:\n",
    "            total_value += item.value\n",
    "            remaining_capacity -= item.weight\n",
    "        else:\n",
    "            total_value += item.value * (remaining_capacity / item.weight)\n",
    "            break\n",
    "    \n",
    "    return total_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_approach(problem, iterations=1000, seed=None):\n",
    "    \"\"\"\n",
    "    Multi-start randomized approach for the 0-1 Knapsack problem\n",
    "    \n",
    "    Generates multiple random solutions by shuffling item order\n",
    "    and adding them greedily. Keeps the best solution found.\n",
    "    \n",
    "    Strategy:\n",
    "    - At each iteration, randomly shuffle items\n",
    "    - Build a greedy solution with this order\n",
    "    - Keep the best solution among all iterations\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "        iterations: Number of random solutions to generate (default: 1000)\n",
    "        seed: Random seed for reproducibility (optional)\n",
    "    \n",
    "    Returns:\n",
    "        Solution object (quality depends on number of iterations)\n",
    "    \n",
    "    Note:\n",
    "        Simple to implement, good for quick exploration,\n",
    "        but no quality guarantee\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    best_value = 0\n",
    "    best_weight = 0\n",
    "    best_items = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        indices = list(range(problem.n))\n",
    "        random.shuffle(indices)\n",
    "        \n",
    "        selected = []\n",
    "        total_weight = 0\n",
    "        total_value = 0\n",
    "        \n",
    "        for idx in indices:\n",
    "            item = problem.items[idx]\n",
    "            if total_weight + item.weight <= problem.capacity:\n",
    "                selected.append(idx)\n",
    "                total_weight += item.weight\n",
    "                total_value += item.value\n",
    "        \n",
    "        if total_value > best_value:\n",
    "            best_value = total_value\n",
    "            best_weight = total_weight\n",
    "            best_items = selected\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    sol = Solution(best_items, best_value, best_weight, time_taken)\n",
    "    sol.usage_percent = (best_weight / problem.capacity) * 100 if problem.capacity > 0 else 0\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_algorithm(problem, population_size=100, generations=50, \n",
    "                     crossover_rate=0.8, mutation_rate=0.02, \n",
    "                     elitism_count=5, seed=None):\n",
    "    \"\"\"\n",
    "    Genetic Algorithm for the 0-1 Knapsack problem\n",
    "    \n",
    "    Metaheuristic inspired by natural evolution. Maintains a\n",
    "    population of solutions that evolve through selection, crossover\n",
    "    and mutation over multiple generations.\n",
    "    \n",
    "    Genetic operators:\n",
    "    - Tournament selection (controlled selective pressure)\n",
    "    - Two-point crossover (space exploration)\n",
    "    - Bit-flip mutation (diversification)\n",
    "    - Elitism (preservation of best solutions)\n",
    "\n",
    "    Args:\n",
    "        problem: Problem instance (Problem object)\n",
    "        population_size: Population size (number of chromosomes)\n",
    "        generations: Number of generations (iterations)\n",
    "        crossover_rate: Crossover probability (0.0 to 1.0)\n",
    "        mutation_rate: Mutation probability per gene (0.0 to 1.0)\n",
    "        elitism_count: Number of best solutions to preserve\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Solution object (good quality without optimality guarantee)\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    n = problem.n\n",
    "    capacity = problem.capacity\n",
    "    items = problem.items\n",
    "    \n",
    "    # === 1. FITNESS FUNCTION ===\n",
    "    def fitness(chromosome):\n",
    "        \"\"\"Quality of a chromosome (solution)\"\"\"\n",
    "        total_weight = sum(chromosome[i] * items[i].weight for i in range(n))\n",
    "        total_value = sum(chromosome[i] * items[i].value for i in range(n))\n",
    "        \n",
    "        # Penalty if capacity exceeded\n",
    "        if total_weight > capacity:\n",
    "            # Penalty proportional to excess\n",
    "            penalty = (total_weight - capacity) * 10\n",
    "            return max(0, total_value - penalty)\n",
    "        return total_value\n",
    "    \n",
    "    # INITIAL POPULATION\n",
    "    def create_initial_population():\n",
    "        \"\"\"Creates initial population with different strategies\"\"\"\n",
    "        population = []\n",
    "        \n",
    "        # 50% random solutions\n",
    "        for _ in range(population_size // 2):\n",
    "            chromosome = [random.randint(0, 1) for _ in range(n)]\n",
    "            population.append(chromosome)\n",
    "        \n",
    "        # 25% greedy solutions (ratio)\n",
    "        sorted_indices = sorted(range(n), key=lambda i: items[i].ratio(), reverse=True)\n",
    "        for _ in range(population_size // 4):\n",
    "            chromosome = [0] * n\n",
    "            weight = 0\n",
    "            for idx in sorted_indices:\n",
    "                if weight + items[idx].weight <= capacity and random.random() > 0.3:\n",
    "                    chromosome[idx] = 1\n",
    "                    weight += items[idx].weight\n",
    "            population.append(chromosome)\n",
    "        \n",
    "        # 25% solutions with variable density\n",
    "        for _ in range(population_size - len(population)):\n",
    "            chromosome = [0] * n\n",
    "            density = random.uniform(0.2, 0.8)\n",
    "            weight = 0\n",
    "            for i in range(n):\n",
    "                if random.random() < density and weight + items[i].weight <= capacity:\n",
    "                    chromosome[i] = 1\n",
    "                    weight += items[i].weight\n",
    "            population.append(chromosome)\n",
    "        \n",
    "        return population\n",
    "    \n",
    "    # TOURNAMENT SELECTION\n",
    "    def tournament_selection(population, fitnesses, tournament_size=3):\n",
    "        \"\"\"Selects an individual by tournament\"\"\"\n",
    "        tournament_indices = random.sample(range(len(population)), tournament_size)\n",
    "        tournament_fitnesses = [fitnesses[i] for i in tournament_indices]\n",
    "        winner_idx = tournament_indices[tournament_fitnesses.index(max(tournament_fitnesses))]\n",
    "        return population[winner_idx]\n",
    "    \n",
    "    # CROSSOVER\n",
    "    def crossover(parent1, parent2):\n",
    "        \"\"\"Two-point crossover\"\"\"\n",
    "        if random.random() > crossover_rate:\n",
    "            return parent1[:], parent2[:]\n",
    "        \n",
    "        # Two cut points\n",
    "        point1 = random.randint(1, n - 2)\n",
    "        point2 = random.randint(point1 + 1, n - 1)\n",
    "        \n",
    "        child1 = parent1[:point1] + parent2[point1:point2] + parent1[point2:]\n",
    "        child2 = parent2[:point1] + parent1[point1:point2] + parent2[point2:]\n",
    "        \n",
    "        return child1, child2\n",
    "    \n",
    "    # MUTATION\n",
    "    def mutate(chromosome):\n",
    "        \"\"\"Bit-flip mutation\"\"\"\n",
    "        mutated = chromosome[:]\n",
    "        for i in range(n):\n",
    "            if random.random() < mutation_rate:\n",
    "                mutated[i] = 1 - mutated[i]  # Flip 0->1 or 1->0\n",
    "        return mutated\n",
    "    \n",
    "    # MAIN ALGORITHM\n",
    "    population = create_initial_population()\n",
    "    best_chromosome = None\n",
    "    best_fitness = -1\n",
    "    \n",
    "    for gen in range(generations):\n",
    "        # Population evaluation\n",
    "        fitnesses = [fitness(chromo) for chromo in population]\n",
    "        \n",
    "        # Update best solution\n",
    "        gen_best_idx = fitnesses.index(max(fitnesses))\n",
    "        gen_best_fitness = fitnesses[gen_best_idx]\n",
    "        \n",
    "        if gen_best_fitness > best_fitness:\n",
    "            best_fitness = gen_best_fitness\n",
    "            best_chromosome = population[gen_best_idx][:]\n",
    "        \n",
    "        # Sort by fitness (for elitism)\n",
    "        sorted_indices = sorted(range(len(population)), key=lambda i: fitnesses[i], reverse=True)\n",
    "        \n",
    "        # New generation\n",
    "        new_population = []\n",
    "        \n",
    "        # Elitism: keep the best\n",
    "        for i in range(elitism_count):\n",
    "            new_population.append(population[sorted_indices[i]][:])\n",
    "        \n",
    "        # Generate rest of population\n",
    "        while len(new_population) < population_size:\n",
    "            # Selection\n",
    "            parent1 = tournament_selection(population, fitnesses)\n",
    "            parent2 = tournament_selection(population, fitnesses)\n",
    "            \n",
    "            # Crossover\n",
    "            child1, child2 = crossover(parent1, parent2)\n",
    "            \n",
    "            # Mutation\n",
    "            child1 = mutate(child1)\n",
    "            child2 = mutate(child2)\n",
    "            \n",
    "            new_population.append(child1)\n",
    "            if len(new_population) < population_size:\n",
    "                new_population.append(child2)\n",
    "        \n",
    "        population = new_population\n",
    "    \n",
    "    # BEST SOLUTION\n",
    "    selected_items = [i for i in range(n) if best_chromosome[i] == 1]\n",
    "    total_value = sum(items[i].value for i in selected_items)\n",
    "    total_weight = sum(items[i].weight for i in selected_items)\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    sol = Solution(selected_items, total_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / capacity * 100) if capacity > 0 else 0\n",
    "    \n",
    "    return sol\n",
    "\n",
    "\n",
    "def genetic_algorithm_adaptive(problem):\n",
    "    \"\"\"\n",
    "    Adaptive version of the genetic algorithm\n",
    "    \n",
    "    Automatically adjusts parameters (population size,\n",
    "    number of generations, mutation rate) according to problem\n",
    "    size for a good quality/time tradeoff.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object\n",
    "    \n",
    "    Note:\n",
    "        - Small instances (n≤50): finer exploration\n",
    "        - Large instances (n>1000): faster convergence\n",
    "    \"\"\"\n",
    "    n = problem.n\n",
    "    \n",
    "    if n <= 50:\n",
    "        return genetic_algorithm(problem, population_size=50, generations=30, mutation_rate=0.03)\n",
    "    elif n <= 100:\n",
    "        return genetic_algorithm(problem, population_size=80, generations=40, mutation_rate=0.02)\n",
    "    elif n <= 500:\n",
    "        return genetic_algorithm(problem, population_size=100, generations=50, mutation_rate=0.02)\n",
    "    elif n <= 1000:\n",
    "        return genetic_algorithm(problem, population_size=120, generations=40, mutation_rate=0.01)\n",
    "    else:\n",
    "        return genetic_algorithm(problem, population_size=150, generations=30, mutation_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.1 Simulated Annealing\n",
    "\n",
    "**Principle:** Inspired by metallurgical annealing, the algorithm explores the solution space by sometimes accepting worse solutions to escape local optima. The probability of accepting a worse solution decreases with the \"temperature\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_annealing(problem, initial_temp=1000, cooling_rate=0.995, \n",
    "                        min_temp=1, max_iterations=10000, seed=None):\n",
    "    \"\"\"\n",
    "    Simulated Annealing for the 0-1 Knapsack\n",
    "    \n",
    "    Principle:\n",
    "    - Start with an initial solution (greedy)\n",
    "    - At each iteration, generate a neighbor by flipping a bit\n",
    "    - Always accept improvements\n",
    "    - Accept degradations with probability exp(-ΔE/T)\n",
    "    - Temperature T decreases progressively (cooling)\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance\n",
    "        initial_temp: Initial temperature (controls exploration)\n",
    "        cooling_rate: Cooling rate (0.9 to 0.999)\n",
    "        min_temp: Minimum temperature (stopping criterion)\n",
    "        max_iterations: Maximum number of iterations\n",
    "        seed: Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "        Solution object\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "    \n",
    "    n = problem.n\n",
    "    capacity = problem.capacity\n",
    "    items = problem.items\n",
    "    \n",
    "    # === EVALUATION FUNCTION ===\n",
    "    def evaluate(solution):\n",
    "        \"\"\"Computes value and weight of a solution (list of 0/1)\"\"\"\n",
    "        total_value = sum(solution[i] * items[i].value for i in range(n))\n",
    "        total_weight = sum(solution[i] * items[i].weight for i in range(n))\n",
    "        return total_value, total_weight\n",
    "    \n",
    "    def fitness(solution):\n",
    "        \"\"\"Fitness with penalty if capacity exceeded\"\"\"\n",
    "        value, weight = evaluate(solution)\n",
    "        if weight > capacity:\n",
    "            # Penalty proportional to excess\n",
    "            return value - (weight - capacity) * 10\n",
    "        return value\n",
    "    \n",
    "    # === INITIAL SOLUTION (Greedy by ratio) ===\n",
    "    current_solution = [0] * n\n",
    "    sorted_indices = sorted(range(n), key=lambda i: items[i].ratio(), reverse=True)\n",
    "    current_weight = 0\n",
    "    for idx in sorted_indices:\n",
    "        if current_weight + items[idx].weight <= capacity:\n",
    "            current_solution[idx] = 1\n",
    "            current_weight += items[idx].weight\n",
    "    \n",
    "    current_fitness = fitness(current_solution)\n",
    "    best_solution = current_solution[:]\n",
    "    best_fitness = current_fitness\n",
    "    \n",
    "    # === MAIN LOOP ===\n",
    "    temperature = initial_temp\n",
    "    iteration = 0\n",
    "    \n",
    "    while temperature > min_temp and iteration < max_iterations:\n",
    "        # Generate a neighbor by flipping a random bit\n",
    "        neighbor = current_solution[:]\n",
    "        flip_idx = random.randint(0, n - 1)\n",
    "        neighbor[flip_idx] = 1 - neighbor[flip_idx]\n",
    "        \n",
    "        neighbor_fitness = fitness(neighbor)\n",
    "        \n",
    "        # Compute energy difference\n",
    "        delta = neighbor_fitness - current_fitness\n",
    "        \n",
    "        # Acceptance decision\n",
    "        if delta > 0:\n",
    "            # Improvement: always accept\n",
    "            current_solution = neighbor\n",
    "            current_fitness = neighbor_fitness\n",
    "        else:\n",
    "            # Degradation: accept with probability exp(delta/T)\n",
    "            acceptance_prob = math.exp(delta / temperature)\n",
    "            if random.random() < acceptance_prob:\n",
    "                current_solution = neighbor\n",
    "                current_fitness = neighbor_fitness\n",
    "        \n",
    "        # Update best solution\n",
    "        if current_fitness > best_fitness:\n",
    "            # Check that solution is valid\n",
    "            _, weight = evaluate(current_solution)\n",
    "            if weight <= capacity:\n",
    "                best_solution = current_solution[:]\n",
    "                best_fitness = current_fitness\n",
    "        \n",
    "        # Cooling\n",
    "        temperature *= cooling_rate\n",
    "        iteration += 1\n",
    "    \n",
    "    # === FINAL RESULT ===\n",
    "    # Ensure best solution is valid\n",
    "    selected_items = [i for i in range(n) if best_solution[i] == 1]\n",
    "    total_value = sum(items[i].value for i in selected_items)\n",
    "    total_weight = sum(items[i].weight for i in selected_items)\n",
    "    \n",
    "    # Repair if necessary (remove items if overweight)\n",
    "    if total_weight > capacity:\n",
    "        # Sort by increasing ratio and remove\n",
    "        selected_sorted = sorted(selected_items, key=lambda i: items[i].ratio())\n",
    "        while total_weight > capacity and selected_sorted:\n",
    "            remove_idx = selected_sorted.pop(0)\n",
    "            total_weight -= items[remove_idx].weight\n",
    "            total_value -= items[remove_idx].value\n",
    "            selected_items.remove(remove_idx)\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    sol = Solution(selected_items, total_value, total_weight, time_taken)\n",
    "    sol.usage_percent = (total_weight / capacity * 100) if capacity > 0 else 0\n",
    "    sol.iterations = iteration\n",
    "    sol.final_temperature = temperature\n",
    "    \n",
    "    return sol\n",
    "\n",
    "\n",
    "def simulated_annealing_adaptive(problem):\n",
    "    \"\"\"\n",
    "    Adaptive version of Simulated Annealing\n",
    "    \n",
    "    Automatically adjusts parameters (initial temperature,\n",
    "    cooling rate, number of iterations) according to problem\n",
    "    size for a good quality/time tradeoff.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object) containing\n",
    "                 items and knapsack capacity\n",
    "    \n",
    "    Returns:\n",
    "        Solution object\n",
    "    \n",
    "    Note:\n",
    "        - Small instances: fast cooling, fine exploration\n",
    "        - Large instances: slow cooling, more iterations\n",
    "    \"\"\"\n",
    "    n = problem.n\n",
    "    \n",
    "    if n <= 50:\n",
    "        return simulated_annealing(problem, initial_temp=500, cooling_rate=0.99, max_iterations=5000)\n",
    "    elif n <= 200:\n",
    "        return simulated_annealing(problem, initial_temp=1000, cooling_rate=0.995, max_iterations=10000)\n",
    "    elif n <= 1000:\n",
    "        return simulated_annealing(problem, initial_temp=2000, cooling_rate=0.997, max_iterations=15000)\n",
    "    else:\n",
    "        return simulated_annealing(problem, initial_temp=5000, cooling_rate=0.999, max_iterations=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 FTPAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fptas(problem, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    FPTAS (Fully Polynomial-Time Approximation Scheme) for the Knapsack problem.\n",
    "    \n",
    "    Guarantee: Returns a solution with value ≥ (1-ε) × OPT\n",
    "    \n",
    "    Idea: Scale the values to reduce the DP problem size,\n",
    "    then solve the reduced problem exactly.\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance (Problem object)\n",
    "        epsilon: Approximation parameter (0 < ε < 1)\n",
    "                Smaller ε gives better approximation (but slower)\n",
    "    \n",
    "    Returns:\n",
    "        Solution object\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    n = problem.n\n",
    "    items = problem.items\n",
    "    capacity = problem.capacity\n",
    "    \n",
    "    if epsilon <= 0 or epsilon >= 1:\n",
    "        print(f\"FPTAS: epsilon must be in ]0,1[, received {epsilon}\")\n",
    "        return None\n",
    "    \n",
    "    if n == 0:\n",
    "        return SimpleNamespace(\n",
    "            selected_items=[],\n",
    "            total_value=0,\n",
    "            total_weight=0,\n",
    "            time=time.time() - start_time,\n",
    "            usage_percent=0,\n",
    "            epsilon=epsilon,\n",
    "            scaling_factor=0\n",
    "        )\n",
    "    \n",
    "    v_max = max(item.value for item in items)\n",
    "    \n",
    "    # Scaling factor: K = (ε × v_max) / n\n",
    "    # This ensures that the sum of scaled values is ≤ n²/ε\n",
    "    K = (epsilon * v_max) / n\n",
    "    \n",
    "    # If K too small, keep original values\n",
    "    if K < 1e-10:\n",
    "        K = 1e-10\n",
    "    \n",
    "    # Create scaled values (floor)\n",
    "    # Also store original index in items list\n",
    "    scaled_items = []\n",
    "    for idx, item in enumerate(items):\n",
    "        scaled_value = int(item.value / K)  # Floor\n",
    "        scaled_items.append({\n",
    "            'idx': idx,  # Index in items list\n",
    "            'weight': item.weight,\n",
    "            'value': item.value,\n",
    "            'scaled_value': scaled_value\n",
    "        })\n",
    "    \n",
    "    # Maximum sum of scaled values\n",
    "    V_scaled = sum(si['scaled_value'] for si in scaled_items)\n",
    "    \n",
    "    # Memory protection\n",
    "    if V_scaled > 1_000_000:\n",
    "        print(f\"FPTAS Skip: V_scaled too large ({V_scaled:,})\")\n",
    "        return None\n",
    "    \n",
    "    estimated_mb = (n * V_scaled * 8) / (1024 * 1024)\n",
    "    if estimated_mb > 200:  # Max 200 MB\n",
    "        print(f\"FPTAS Skip: estimated memory too large ({estimated_mb:.0f} MB)\")\n",
    "        return None\n",
    "    \n",
    "    V_scaled = int(V_scaled)\n",
    "    \n",
    "    # DP on scaled values\n",
    "    # dp[v] = minimum weight to achieve exactly scaled value v\n",
    "    # We use a 1D space-optimized version\n",
    "    INF = float('inf')\n",
    "    dp = [INF] * (V_scaled + 1)\n",
    "    dp[0] = 0\n",
    "    \n",
    "    # parent[v] = (previous_value, idx_item) to reconstruct solution\n",
    "    parent = [None] * (V_scaled + 1)\n",
    "    \n",
    "    for idx, si in enumerate(scaled_items):\n",
    "        sv = si['scaled_value']\n",
    "        w = si['weight']\n",
    "        \n",
    "        # Backward traversal to avoid reusing same item\n",
    "        for v in range(V_scaled, sv - 1, -1):\n",
    "            prev_v = v - sv\n",
    "            if dp[prev_v] != INF:\n",
    "                new_weight = dp[prev_v] + w\n",
    "                if new_weight <= capacity and new_weight < dp[v]:\n",
    "                    dp[v] = new_weight\n",
    "                    parent[v] = (prev_v, idx)\n",
    "    \n",
    "    # Find best reachable scaled value\n",
    "    best_scaled_value = 0\n",
    "    for v in range(V_scaled + 1):\n",
    "        if dp[v] <= capacity:\n",
    "            best_scaled_value = v\n",
    "    \n",
    "    # Solution reconstruction\n",
    "    selected_indices = []\n",
    "    v = best_scaled_value\n",
    "    while v > 0 and parent[v] is not None:\n",
    "        prev_v, idx = parent[v]\n",
    "        # idx is index in scaled_items, we retrieve original item index\n",
    "        original_idx = scaled_items[idx]['idx']\n",
    "        selected_indices.append(original_idx)\n",
    "        v = prev_v\n",
    "    \n",
    "    # Compute real value and weight (selected_indices now contains original indices)\n",
    "    total_value = sum(items[idx].value for idx in selected_indices)\n",
    "    total_weight = sum(items[idx].weight for idx in selected_indices)\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    \n",
    "    sol = SimpleNamespace(\n",
    "        selected_items=selected_indices,\n",
    "        total_value=total_value,\n",
    "        total_weight=total_weight,\n",
    "        time=time_taken,\n",
    "        usage_percent=(total_weight / capacity * 100) if capacity > 0 else 0,\n",
    "        epsilon=epsilon,\n",
    "        scaling_factor=K\n",
    "    )\n",
    "    \n",
    "    return sol\n",
    "\n",
    "# Alias for compatibility with old name\n",
    "ftpas = fptas\n",
    "\n",
    "\n",
    "def fptas_adaptive(problem, time_budget=None):\n",
    "    \"\"\"\n",
    "    Adaptive FPTAS: adjusts epsilon according to problem size.\n",
    "    \n",
    "    For small problems, we use a small epsilon (better quality).\n",
    "    For large problems, we increase epsilon (faster).\n",
    "    \n",
    "    Args:\n",
    "        problem: Problem instance\n",
    "        time_budget: Optional time budget (not used for now)\n",
    "    \n",
    "    Returns:\n",
    "        Solution object\n",
    "    \"\"\"\n",
    "    n = problem.n\n",
    "    \n",
    "    if n <= 50:\n",
    "        epsilon = 0.05  # Very precise for small instances\n",
    "    elif n <= 100:\n",
    "        epsilon = 0.1\n",
    "    elif n <= 500:\n",
    "        epsilon = 0.2\n",
    "    else:\n",
    "        epsilon = 0.3  # Faster for large instances\n",
    "    \n",
    "    return fptas(problem, epsilon)\n",
    "\n",
    "# Alias for compatibility\n",
    "ftpas_adaptive = fptas_adaptive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Benchmarking System\n",
    "\n",
    "### 5.1 Test Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_N_CORRELATED = 1000 \n",
    "\n",
    "INCLUDE_GENERATED = True   # Include generated benchmarks (benchmarks/generated/)\n",
    "\n",
    "\n",
    "def discover_benchmarks(base_path='benchmarks', max_n_correlated=None):\n",
    "    \"\"\"\n",
    "    Automatically discovers all available benchmark files.\n",
    "    Includes: low_dimension, large_scale, generated\n",
    "    \n",
    "    Args:\n",
    "        base_path: Path to benchmarks folder\n",
    "        max_n_correlated: Max size for correlated benchmarks (None = uses MAX_N_CORRELATED)\n",
    "    \n",
    "    Returns:\n",
    "        dict: Structure containing benchmarks organized by category\n",
    "    \"\"\"\n",
    "    if max_n_correlated is None:\n",
    "        max_n_correlated = MAX_N_CORRELATED\n",
    "        \n",
    "    base = Path(base_path)\n",
    "    \n",
    "    if not base.exists():\n",
    "        print(f\"Folder '{base_path}' not found\")\n",
    "        return None\n",
    "    \n",
    "    structure = {\n",
    "        'base_path': str(base),\n",
    "        'benchmarks': {}\n",
    "    }\n",
    "    \n",
    "    # Scan low_dimension and large_scale - WITHOUT size limit\n",
    "    simple_categories = ['low_dimension', 'large_scale']\n",
    "    \n",
    "    for category in simple_categories:\n",
    "        category_path = base / category\n",
    "        if not category_path.exists():\n",
    "            continue\n",
    "            \n",
    "        for file_path in category_path.glob('*.txt'):\n",
    "            filename = file_path.name\n",
    "            \n",
    "            if category == 'low_dimension':\n",
    "                parts = filename.replace('.txt', '').split('_')\n",
    "                try:\n",
    "                    n = int(parts[3])\n",
    "                    cap = int(parts[4])\n",
    "                except (IndexError, ValueError):\n",
    "                    continue\n",
    "            else:\n",
    "                parts = filename.replace('.txt', '').split('_')\n",
    "                try:\n",
    "                    n = int(parts[2])\n",
    "                    cap = int(parts[3])\n",
    "                except (IndexError, ValueError):\n",
    "                    continue\n",
    "            \n",
    "            # NO size filter for large_scale and low_dimension\n",
    "            key = f\"{category}_{filename}\"\n",
    "            structure['benchmarks'][key] = {\n",
    "                'path': str(file_path),\n",
    "                'correlation': category,\n",
    "                'size': f\"n={n}\",\n",
    "                'capacity': f\"c={cap}\",\n",
    "                'n': n,\n",
    "                'capacity_value': cap,\n",
    "                'format': 'standard'\n",
    "            }\n",
    "    \n",
    "    # Scan generated/ - .txt files generated by generate_benchmarks()\n",
    "    if INCLUDE_GENERATED:\n",
    "        generated_path = base / 'generated'\n",
    "        if generated_path.exists():\n",
    "            for file_path in generated_path.glob('*.txt'):\n",
    "                filename = file_path.name\n",
    "                # Format: {correlation}_n{n}_c{capacity}.txt or {correlation}_n{n}_c{capacity}_{index}.txt\n",
    "                parts = filename.replace('.txt', '').split('_')\n",
    "                try:\n",
    "                    # Find n and c in name\n",
    "                    correlation = parts[0]\n",
    "                    n = None\n",
    "                    cap = None\n",
    "                    for part in parts:\n",
    "                        if part.startswith('n') and part[1:].isdigit():\n",
    "                            n = int(part[1:])\n",
    "                        elif part.startswith('c') and part[1:].isdigit():\n",
    "                            cap = int(part[1:])\n",
    "                    \n",
    "                    if n is None or cap is None:\n",
    "                        continue\n",
    "                    \n",
    "                    key = f\"generated_{filename}\"\n",
    "                    structure['benchmarks'][key] = {\n",
    "                        'path': str(file_path),\n",
    "                        'correlation': f\"generated_{correlation}\",\n",
    "                        'size': f\"n={n}\",\n",
    "                        'capacity': f\"c={cap}\",\n",
    "                        'n': n,\n",
    "                        'capacity_value': cap,\n",
    "                        'format': 'standard'\n",
    "                    }\n",
    "                except (IndexError, ValueError):\n",
    "                    continue\n",
    "    \n",
    "    print(f\"Discovered {len(structure['benchmarks'])} benchmarks\")\n",
    "    return structure\n",
    "\n",
    "\n",
    "def parse_benchmark_file(filepath):\n",
    "    \"\"\"Parses a benchmark .txt file\n",
    "    \n",
    "    Standard format (.txt): \n",
    "    - Line 1: n capacity (space-separated)\n",
    "    - Following lines: value weight (profit then weight)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            lines = [line.strip() for line in f.readlines()]\n",
    "        \n",
    "        first_line_parts = lines[0].split()\n",
    "        n = int(first_line_parts[0])\n",
    "        capacity = int(first_line_parts[1])\n",
    "        \n",
    "        items = []\n",
    "        for i in range(n):\n",
    "            parts = lines[1 + i].split()\n",
    "            value = int(parts[0])\n",
    "            weight = int(parts[1])\n",
    "            items.append(Item(i, weight, value))\n",
    "        \n",
    "        return Problem(items, capacity)\n",
    "    except Exception as e:\n",
    "        print(f\"Parsing error {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Initialize benchmark structure\n",
    "BENCHMARK_STRUCTURE = discover_benchmarks()\n",
    "\n",
    "if BENCHMARK_STRUCTURE:\n",
    "    print(f\"\\nCurrent configuration:\")\n",
    "    print(f\"  - large_scale & low_dimension: ALL files\")\n",
    "    print(f\"  - generated: files generated by generate_benchmarks()\")\n",
    "    print(f\"\\nAvailable categories:\")\n",
    "    categories = {}\n",
    "    sizes_by_cat = {}\n",
    "    for key, info in BENCHMARK_STRUCTURE['benchmarks'].items():\n",
    "        cat = info['correlation']\n",
    "        if cat not in categories:\n",
    "            categories[cat] = 0\n",
    "            sizes_by_cat[cat] = set()\n",
    "        categories[cat] += 1\n",
    "        sizes_by_cat[cat].add(info['n'])\n",
    "    for cat, count in sorted(categories.items()):\n",
    "        sizes = sorted(sizes_by_cat[cat])\n",
    "        print(f\"  - {cat}: {count} files (n={sizes})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION OF ALGORITHMS TO RUN\n",
    "# =============================================================================\n",
    "# Set True to enable an algorithm, False to disable it\n",
    "# max_n = maximum size to run the algo (float('inf') = no limit)\n",
    "\n",
    "ALGORITHMS_CONFIG = {\n",
    "    # Exact algorithms\n",
    "    'Brute Force':          {'enabled': True, 'max_n': 25},\n",
    "    'Dynamic Programming':  {'enabled': True, 'max_n': 5000},\n",
    "    'DP Top-Down':          {'enabled': True, 'max_n': 5000},\n",
    "    'Branch and Bound':     {'enabled': True, 'max_n': 500},\n",
    "    \n",
    "    # Greedy algorithms\n",
    "    'Greedy Ratio':         {'enabled': True,  'max_n': float('inf')},\n",
    "    'Greedy Value':         {'enabled': True,  'max_n': float('inf')},\n",
    "    'Greedy Weight':        {'enabled': True,  'max_n': float('inf')},\n",
    "    'Fractional Knapsack':  {'enabled': True,  'max_n': float('inf')},\n",
    "    \n",
    "    # Stochastic/metaheuristic algorithms\n",
    "    'Randomized':           {'enabled': True,  'max_n': float('inf')},\n",
    "    'Genetic Algorithm':    {'enabled': True,  'max_n': float('inf')},\n",
    "    'Genetic Adaptive':     {'enabled': True,  'max_n': float('inf')},\n",
    "    'Simulated Annealing':  {'enabled': True,  'max_n': float('inf')},\n",
    "    'SA Adaptive':          {'enabled': True,  'max_n': float('inf')},\n",
    "    \n",
    "    # FPTAS (approximation)\n",
    "    'FPTAS (ε=0.1)':        {'enabled': True, 'max_n': float('inf')},\n",
    "    'FPTAS (ε=0.05)':       {'enabled': True, 'max_n': float('inf')},\n",
    "    'FPTAS Adaptive':       {'enabled': True, 'max_n': float('inf')},\n",
    "}\n",
    "\n",
    "# Dictionary of algorithm functions\n",
    "ALGORITHMS_FUNCS = {\n",
    "    'Brute Force':          brute_force,\n",
    "    'Dynamic Programming':  dynamic_programming,\n",
    "    'DP Top-Down':          dynamic_programming_topdown,\n",
    "    'Branch and Bound':     branch_and_bound,\n",
    "    'Greedy Ratio':         greedy_by_ratio,\n",
    "    'Greedy Value':         greedy_by_value,\n",
    "    'Greedy Weight':        greedy_by_weight,\n",
    "    'Fractional Knapsack':  fractional_knapsack,\n",
    "    'Randomized':           lambda p: randomized_approach(p, iterations=100),\n",
    "    'Genetic Algorithm':    lambda p: genetic_algorithm(p, population_size=100, generations=50),\n",
    "    'Genetic Adaptive':     genetic_algorithm_adaptive,\n",
    "    'Simulated Annealing':  lambda p: simulated_annealing(p, initial_temp=1000, cooling_rate=0.995),\n",
    "    'SA Adaptive':          simulated_annealing_adaptive,\n",
    "    'FPTAS (ε=0.1)':        lambda p: ftpas(p, epsilon=0.1),\n",
    "    'FPTAS (ε=0.05)':       lambda p: ftpas(p, epsilon=0.05),\n",
    "    'FPTAS Adaptive':       ftpas_adaptive,\n",
    "}\n",
    "\n",
    "# Automatic construction of ALL_ALGORITHMS from config\n",
    "ALL_ALGORITHMS = [\n",
    "    (name, ALGORITHMS_FUNCS[name], config['max_n'])\n",
    "    for name, config in ALGORITHMS_CONFIG.items()\n",
    "    if config['enabled']\n",
    "]\n",
    "\n",
    "# Display selected algorithms\n",
    "print(\"Enabled algorithms:\")\n",
    "for name, _, max_n in ALL_ALGORITHMS:\n",
    "    max_n_str = \"∞\" if max_n == float('inf') else str(max_n)\n",
    "    print(f\"  ✓ {name} (max_n={max_n_str})\")\n",
    "print(f\"\\nTotal: {len(ALL_ALGORITHMS)} selected algorithms\")\n",
    "\n",
    "\n",
    "def should_run_algorithm(algo_name, n, max_n, correlation=None):\n",
    "    \"\"\"Determines if an algorithm should be executed based on size and correlation\"\"\"\n",
    "    # Brute Force uniquement sur low_dimension\n",
    "    if algo_name == 'Brute Force' and correlation != 'low_dimension':\n",
    "        return False\n",
    "    return n <= max_n\n",
    "\n",
    "\n",
    "def run_benchmark(benchmark_info, algorithms=None, timeout=300):\n",
    "    \"\"\"\n",
    "    Runs a benchmark on a file.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results for each algorithm\n",
    "    \"\"\"\n",
    "    if algorithms is None:\n",
    "        algorithms = ALL_ALGORITHMS\n",
    "    \n",
    "    problem = parse_benchmark_file(benchmark_info['path'])\n",
    "    if problem is None:\n",
    "        return None\n",
    "    \n",
    "    results = {\n",
    "        'info': benchmark_info,\n",
    "        'n': problem.n,\n",
    "        'capacity': problem.capacity,\n",
    "        'algorithms': {}\n",
    "    }\n",
    "    \n",
    "    for algo_name, algo_func, max_n in algorithms:\n",
    "        if not should_run_algorithm(algo_name, problem.n, max_n):\n",
    "            results['algorithms'][algo_name] = {'skipped': True, 'reason': f'n={problem.n} > max_n={max_n}'}\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # ERROR HANDLING\n",
    "            start = time.time()\n",
    "            sol = algo_func(problem)\n",
    "            elapsed = time.time() - start\n",
    "            \n",
    "            # Check timeout\n",
    "            if elapsed > timeout:\n",
    "                results['algorithms'][algo_name] = {\n",
    "                    'skipped': True,\n",
    "                    'reason': f'timeout (>{timeout}s)'\n",
    "                }\n",
    "                print(f\"{algo_name}: timeout ({elapsed:.1f}s)\")\n",
    "                continue\n",
    "            \n",
    "            # Check if algo returned None (internal protection)\n",
    "            if sol is None:\n",
    "                results['algorithms'][algo_name] = {\n",
    "                    'skipped': True,\n",
    "                    'reason': 'protection_triggered'\n",
    "                }\n",
    "                continue\n",
    "            # END ERROR HANDLING\n",
    "            \n",
    "            results['algorithms'][algo_name] = {\n",
    "                'value': sol.total_value,\n",
    "                'weight': sol.total_weight,\n",
    "                'time': sol.time,\n",
    "                'usage': sol.usage_percent,\n",
    "                'items_count': len(sol.selected_items),\n",
    "                'skipped': False\n",
    "            }\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\nManual interruption on {algo_name}\")\n",
    "            results['algorithms'][algo_name] = {\n",
    "                'skipped': True,\n",
    "                'reason': 'interrupted'\n",
    "            }\n",
    "            continue  # Continue with other algorithms\n",
    "            \n",
    "        except MemoryError:\n",
    "            results['algorithms'][algo_name] = {\n",
    "                'skipped': True,\n",
    "                'reason': 'memory_error'\n",
    "            }\n",
    "            print(f\"{algo_name}: Insufficient memory\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            results['algorithms'][algo_name] = {\n",
    "                'skipped': True,\n",
    "                'reason': str(e)\n",
    "            }\n",
    "            print(f\"{algo_name}: {str(e)}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Full Benchmark Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_benchmarks():\n",
    "    \"\"\"\n",
    "    Runs all available benchmarks.\n",
    "    Saves ONLY at the end, no partial saves.\n",
    "    Continues even if error on an algorithm or benchmark.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with all results\n",
    "    \"\"\"\n",
    "    if BENCHMARK_STRUCTURE is None:\n",
    "        print(\"No benchmarks available\")\n",
    "        return None\n",
    "    \n",
    "    all_results = []\n",
    "    total = len(BENCHMARK_STRUCTURE['benchmarks'])\n",
    "    \n",
    "    print(f\"Running {total} benchmarks...\")    \n",
    "    for i, (key, bench_info) in enumerate(BENCHMARK_STRUCTURE['benchmarks'].items(), 1):\n",
    "        print(f\"\\n[{i}/{total}] {bench_info['correlation']} | {bench_info['size']} | {bench_info['capacity']}\")\n",
    "        \n",
    "        try:\n",
    "            # Parse problem\n",
    "            problem = parse_benchmark_file(bench_info['path'])\n",
    "            if problem is None:\n",
    "                print(f\"  ERROR: Cannot parse this benchmark, skipping\")\n",
    "                continue\n",
    "            \n",
    "            # Problem information\n",
    "            print(f\"  n={problem.n}, capacity={problem.capacity}\")\n",
    "            \n",
    "            # Test each algorithm\n",
    "            for algo_name, algo_func, max_n in ALL_ALGORITHMS:\n",
    "                # Check if we should run this algo\n",
    "                if not should_run_algorithm(algo_name, problem.n, max_n, bench_info['correlation']):\n",
    "                    if algo_name == 'Brute Force' and bench_info['correlation'] != 'low_dimension':\n",
    "                        print(f\"  SKIP {algo_name}: only on low_dimension\")\n",
    "                    else:\n",
    "                        print(f\"  SKIP {algo_name}: n={problem.n} > max_n={max_n}\")\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    # Run algorithm\n",
    "                    start_algo = time.time()\n",
    "                    sol = algo_func(problem)\n",
    "                    elapsed = time.time() - start_algo\n",
    "                    \n",
    "                    # If algo takes more than 5 minutes, note it but keep result\n",
    "                    if elapsed > 300:\n",
    "                        print(f\"  WARNING {algo_name}: very long time ({elapsed:.1f}s)\")\n",
    "                    \n",
    "                    # Check if algo returned None (internal protection)\n",
    "                    if sol is None:\n",
    "                        print(f\"  SKIP {algo_name}: protection triggered\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Record result\n",
    "                    row = {\n",
    "                        'correlation': bench_info['correlation'],\n",
    "                        'n': problem.n,\n",
    "                        'capacity_type': bench_info['capacity'],\n",
    "                        'capacity_value': problem.capacity,\n",
    "                        'algorithm': algo_name,\n",
    "                        'value': sol.total_value,\n",
    "                        'time_ms': sol.time * 1000,\n",
    "                        'usage_percent': sol.usage_percent,\n",
    "                        'items_selected': len(sol.selected_items)\n",
    "                    }\n",
    "                    all_results.append(row)\n",
    "                                    \n",
    "                except MemoryError:\n",
    "                    print(f\"  ERROR {algo_name}: Memory error\")\n",
    "                    continue\n",
    "                \n",
    "                except KeyboardInterrupt:    \n",
    "                    if len(all_results) > 0:\n",
    "                        df = pd.DataFrame(all_results)\n",
    "                        df.to_csv('benchmark_results_interrupted.csv', index=False)\n",
    "                        print(\"Emergency save: 'benchmark_results_interrupted.csv'\")\n",
    "                        return df\n",
    "                    else:\n",
    "                        print(\"No results to save\")\n",
    "                        return None\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(f\"  ERROR {algo_name}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR on this benchmark: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if len(all_results) == 0:\n",
    "        print(\"WARNING: No results collected\")\n",
    "        return None\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save\n",
    "    try:\n",
    "        df.to_csv('benchmark_results.csv', index=False)\n",
    "        print(\"Results saved: 'benchmark_results.csv'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR during save: {e}\")\n",
    "        print(\"DataFrame is returned anyway\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Loading Results\n",
    "\n",
    "If benchmarks have already been run, load the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "try:\n",
    "    results_df = run_all_benchmarks()\n",
    "    print(f\"\\nOverview:\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File 'benchmark_results.csv' not found\")\n",
    "    print(\"Run first: results_df = run_all_benchmarks()\")\n",
    "    results_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Simple Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 2: Execution time by size n\n",
    "if results_df is not None:\n",
    "    df = results_df.copy()\n",
    "    \n",
    "    # Average time by algorithm and size n\n",
    "    agg_time = df.groupby(['algorithm', 'n'])['time_ms'].mean().reset_index()\n",
    "    \n",
    "    # Sort by n\n",
    "    agg_time = agg_time.sort_values('n')\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    \n",
    "    # Use lineplot with algorithm as hue (color)\n",
    "    sns.lineplot(data=agg_time, x='n', y='time_ms', hue='algorithm', marker='o', palette='husl', linewidth=2, markersize=8)\n",
    "    \n",
    "    plt.xlabel('Problem size (n)')\n",
    "    plt.ylabel('Average time (ms)')\n",
    "    plt.title('Execution time by problem size')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # X axis with ticks every 1000\n",
    "    max_n = int(agg_time['n'].max())\n",
    "    plt.xticks(range(0, max_n + 1000, 1000))\n",
    "    plt.xlim(0, max_n + 500)\n",
    "    \n",
    "    plt.legend(title='Algorithm', bbox_to_anchor=(1.05,1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"results_df not loaded. Run first the cell that loads 'benchmark_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 2b: Number of files tested by algorithm and size n\n",
    "if results_df is not None:\n",
    "    df = results_df.copy()\n",
    "    \n",
    "    # Count number of files tested by algorithm and size n\n",
    "    # Each DataFrame row represents a test (a file tested by an algorithm)\n",
    "    file_counts = df.groupby(['algorithm', 'n']).size().reset_index(name='nb_files')\n",
    "    \n",
    "    # Create pivot table for better visualization\n",
    "    pivot_counts = file_counts.pivot(index='algorithm', columns='n', values='nb_files').fillna(0).astype(int)\n",
    "    \n",
    "    # Display table\n",
    "    print(\"Number of files tested by algorithm and size n:\")\n",
    "    print(pivot_counts.to_string())\n",
    "    print()\n",
    "    \n",
    "    # Reorder pivot columns in ascending order\n",
    "    pivot_counts = pivot_counts[sorted(pivot_counts.columns)]\n",
    "    \n",
    "    # Calculate total files available for each n\n",
    "    # (the max among all algorithms for each n)\n",
    "    total_files_per_n = pivot_counts.max(axis=0)\n",
    "    \n",
    "    # Create matrix with 3 values: 0 = no files, 1 = partial, 2 = complete\n",
    "    status_matrix = np.zeros_like(pivot_counts.values, dtype=float)\n",
    "    for i in range(len(pivot_counts.index)):\n",
    "        for j in range(len(pivot_counts.columns)):\n",
    "            n_col = pivot_counts.columns[j]\n",
    "            val = pivot_counts.values[i, j]\n",
    "            total = total_files_per_n[n_col]\n",
    "            if val >= total and total > 0:\n",
    "                status_matrix[i, j] = 2  # Green (all files)\n",
    "            elif val > 0:\n",
    "                status_matrix[i, j] = 1  # Yellow (partial)\n",
    "            else:\n",
    "                status_matrix[i, j] = 0  # Red (no files)\n",
    "    \n",
    "    # Heatmap chart with 3 colors\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    # Custom colormap: red (0), yellow (1), green (2)\n",
    "    cmap_3colors = ListedColormap(['#e74c3c', '#f39c12', '#2ecc71'])  # Red, Yellow, Green\n",
    "    \n",
    "    # Use pcolormesh with 3-color colormap\n",
    "    im = ax.pcolormesh(status_matrix, cmap=cmap_3colors, edgecolors='white', linewidth=2, vmin=0, vmax=2)\n",
    "    \n",
    "    # Axes - center ticks in middle of cells\n",
    "    ax.set_xticks(np.arange(len(pivot_counts.columns)) + 0.5)\n",
    "    ax.set_yticks(np.arange(len(pivot_counts.index)) + 0.5)\n",
    "    ax.set_xticklabels([f'n={n}' for n in pivot_counts.columns], fontsize=10)\n",
    "    ax.set_yticklabels(pivot_counts.index, fontsize=10)\n",
    "    \n",
    "    # Rotate x labels\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    \n",
    "    # Add values in each cell (centered in each box)\n",
    "    for i in range(len(pivot_counts.index)):\n",
    "        for j in range(len(pivot_counts.columns)):\n",
    "            val = int(pivot_counts.values[i, j])\n",
    "            n_col = pivot_counts.columns[j]\n",
    "            total = int(total_files_per_n[n_col])\n",
    "            # White text for better readability on colors\n",
    "            ax.text(j + 0.5, i + 0.5, f'{val}/{total}', ha='center', va='center', \n",
    "                   color='white', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    ax.set_xlabel('Size n', fontsize=12)\n",
    "    ax.set_ylabel('Algorithm', fontsize=12)\n",
    "    ax.set_title('Heatmap: Number of files tested by algorithm and size n', fontsize=13, fontweight='bold')\n",
    "    \n",
    "    # Custom legend instead of colorbar\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#2ecc71', edgecolor='white', label='All files tested'),\n",
    "        Patch(facecolor='#f39c12', edgecolor='white', label='Partially tested'),\n",
    "        Patch(facecolor='#e74c3c', edgecolor='white', label='No files tested')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1), fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"results_df not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 3: Scatter Time (X) vs Value (Y), 1 point = 1 algorithm (averages), annotated\n",
    "if results_df is not None:\n",
    "    df = results_df.copy()\n",
    "    # take average time and value by algorithm\n",
    "    summary = df.groupby('algorithm').agg({'time_ms':'mean','value':'mean'}).reset_index()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(summary['time_ms'], summary['value'], s=120, alpha=0.8)\n",
    "    for i, row in summary.iterrows():\n",
    "        plt.text(row['time_ms'], row['value'], row['algorithm'], fontsize=9,\n",
    "                 verticalalignment='bottom', horizontalalignment='right')\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Average time (ms)')\n",
    "    plt.ylabel('Average value')\n",
    "    plt.title('Time vs Quality tradeoff (one point = one algorithm)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"results_df not loaded. Run first the cell that loads 'benchmark_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    df = results_df.copy()\n",
    "    \n",
    "    algorithms = df['algorithm'].unique()\n",
    "    \n",
    "    # colors for the two main categories\n",
    "    colors_cat = {'large_scale':'#1f77b4','low_dimension':'#ff7f0e'}\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        algo_data = df[df['algorithm'] == algo].copy()\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "        fig.suptitle(f'Performance: {algo}', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        # Value by category and size n\n",
    "        if 'category' in algo_data.columns:\n",
    "            agg_value = algo_data.groupby(['category', 'n'])['value'].mean().reset_index()\n",
    "            groups = agg_value['category'].unique()\n",
    "        else:\n",
    "            # fallback to 'correlation' if present\n",
    "            agg_value = algo_data.groupby(['correlation', 'n'])['value'].mean().reset_index()\n",
    "            agg_value = agg_value.rename(columns={'correlation':'category'})\n",
    "            groups = agg_value['category'].unique()\n",
    "\n",
    "        for cat in groups:\n",
    "            cat_data = agg_value[agg_value['category'] == cat]\n",
    "            axes[0].plot(cat_data['n'], cat_data['value'], marker='o', label=cat, linewidth=2,\n",
    "                         color=colors_cat.get(cat, None))\n",
    "        \n",
    "        axes[0].set_xlabel('Size n', fontsize=11)\n",
    "        axes[0].set_ylabel('Average value', fontsize=11)\n",
    "        axes[0].set_title('Value by size and category')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(alpha=0.3)\n",
    "        axes[0].set_xscale('log')\n",
    "        \n",
    "        # Execution time by size n\n",
    "        if 'category' in algo_data.columns:\n",
    "            agg_time = algo_data.groupby(['category', 'n'])['time_ms'].mean().reset_index()\n",
    "        else:\n",
    "            agg_time = algo_data.groupby(['correlation', 'n'])['time_ms'].mean().reset_index()\n",
    "            agg_time = agg_time.rename(columns={'correlation':'category'})\n",
    "\n",
    "        for cat in agg_time['category'].unique():\n",
    "            cat_data = agg_time[agg_time['category'] == cat]\n",
    "            axes[1].plot(cat_data['n'], cat_data['time_ms'], marker='s', label=cat, linewidth=2,\n",
    "                         color=colors_cat.get(cat, None))\n",
    "        \n",
    "        axes[1].set_xlabel('Size n', fontsize=11)\n",
    "        axes[1].set_ylabel('Average time (ms)', fontsize=11)\n",
    "        axes[1].set_title('Execution time by size')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(alpha=0.3)\n",
    "        axes[1].set_xscale('log')\n",
    "        axes[1].set_yscale('log')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        print(f\"\\n{'='*60}\\n\")\n",
    "else:\n",
    "    print(\"results_df not loaded. Run first the cell that loads 'benchmark_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 5: Performance evolution by n for each correlation type\n",
    "if results_df is not None:\n",
    "    df = results_df.copy()\n",
    "    \n",
    "    # Color palette for correlations\n",
    "    corr_colors = {\n",
    "        'uncorrelated': '#2ecc71',\n",
    "        'weakly_correlated': '#f39c12', \n",
    "        'strongly_correlated': '#e74c3c',\n",
    "        'low_dimension': '#3498db',\n",
    "        'large_scale': '#9b59b6'\n",
    "    }\n",
    "    \n",
    "    # Select a few representative algorithms for readability\n",
    "    algos_to_show = ['Dynamic Programming', 'Greedy Ratio', 'Genetic Algorithm', 'Simulated Annealing']\n",
    "    algos_present = [a for a in algos_to_show if a in df['algorithm'].unique()]\n",
    "    \n",
    "    if len(algos_present) > 0:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for idx, algo in enumerate(algos_present[:4]):\n",
    "            ax = axes[idx]\n",
    "            algo_data = df[df['algorithm'] == algo]\n",
    "            \n",
    "            for corr in algo_data['correlation'].unique():\n",
    "                corr_data = algo_data[algo_data['correlation'] == corr]\n",
    "                agg = corr_data.groupby('n').agg({'value': 'mean', 'time_ms': 'mean'}).reset_index()\n",
    "                agg = agg.sort_values('n')\n",
    "                \n",
    "                color = corr_colors.get(corr, '#333')\n",
    "                ax.plot(agg['n'], agg['value'], 'o-', label=corr, color=color, linewidth=2, markersize=6)\n",
    "            \n",
    "            ax.set_xlabel('Size n', fontsize=10)\n",
    "            ax.set_ylabel('Average value', fontsize=10)\n",
    "            ax.set_title(f'{algo}', fontsize=11, fontweight='bold')\n",
    "            ax.legend(fontsize=8)\n",
    "            ax.grid(alpha=0.3)\n",
    "            ax.set_xscale('log')\n",
    "        \n",
    "        plt.suptitle('Value obtained by size and correlation type', fontsize=13, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"results_df not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if results_df is not None:\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    from sklearn.metrics import r2_score\n",
    "    import warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    \n",
    "    df = results_df.copy()\n",
    "    \n",
    "    # Normalize quality\n",
    "    df['max_value_per_instance'] = df.groupby(['n', 'correlation'])['value'].transform('max')\n",
    "    df['relative_quality'] = (df['value'] / df['max_value_per_instance']) * 100\n",
    "    \n",
    "    # Take all algorithms present in the data\n",
    "    all_algos = df['algorithm'].unique().tolist()\n",
    "    \n",
    "    regression_results = []\n",
    "    \n",
    "    # A separate chart for each algorithm\n",
    "    for algo in all_algos:\n",
    "        algo_data = df[df['algorithm'] == algo].copy()\n",
    "        \n",
    "        if len(algo_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Group by size\n",
    "        grouped = algo_data.groupby('n').agg({\n",
    "            'relative_quality': 'mean',\n",
    "            'time_ms': 'mean'\n",
    "        }).reset_index().sort_values('n')\n",
    "        \n",
    "        if len(grouped) < 2:\n",
    "            continue\n",
    "        \n",
    "        X = grouped['n'].values.reshape(-1, 1)\n",
    "        y_quality = grouped['relative_quality'].values\n",
    "        y_time = grouped['time_ms'].values\n",
    "        \n",
    "        # Polynomial regression for quality\n",
    "        poly_features = PolynomialFeatures(degree=2)\n",
    "        X_poly = poly_features.fit_transform(X)\n",
    "        \n",
    "        reg_quality = LinearRegression()\n",
    "        reg_quality.fit(X_poly, y_quality)\n",
    "        y_pred_quality = reg_quality.predict(X_poly)\n",
    "        r2_quality = r2_score(y_quality, y_pred_quality)\n",
    "        \n",
    "        # Regression for time (log-log)\n",
    "        X_log = np.log1p(X)\n",
    "        y_log = np.log1p(y_time)\n",
    "        reg_time = LinearRegression()\n",
    "        reg_time.fit(X_log, y_log)\n",
    "        y_pred_time = np.expm1(reg_time.predict(X_log))\n",
    "        r2_time = r2_score(y_time, y_pred_time)\n",
    "        \n",
    "        # Create individual chart for this algorithm\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        ax2 = ax.twinx()\n",
    "        \n",
    "        # Quality\n",
    "        ax.scatter(grouped['n'], grouped['relative_quality'], color='blue', \n",
    "                  alpha=0.6, s=60, label='Observed quality', zorder=3)\n",
    "        ax.plot(grouped['n'], y_pred_quality, 'b--', linewidth=2, \n",
    "               label=f'Quality Regression (R²={r2_quality:.3f})', zorder=2)\n",
    "        ax.set_xlabel('Problem size (n)', fontsize=11)\n",
    "        ax.set_ylabel('Relative Quality (%)', fontsize=11, color='blue')\n",
    "        ax.tick_params(axis='y', labelcolor='blue')\n",
    "        ax.set_xscale('log')\n",
    "        \n",
    "        # Time\n",
    "        ax2.scatter(grouped['n'], grouped['time_ms'], color='red', \n",
    "                   alpha=0.6, s=60, marker='s', label='Observed time', zorder=3)\n",
    "        ax2.plot(grouped['n'], y_pred_time, 'r--', linewidth=2, \n",
    "                label=f'Time Regression (R²={r2_time:.3f})', zorder=2)\n",
    "        ax2.set_ylabel('Time (ms)', fontsize=11, color='red')\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        ax2.set_yscale('log')\n",
    "        \n",
    "        ax.set_title(f'{algo} - Performance Modeling', \n",
    "                    fontsize=13, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Combined legend\n",
    "        lines1, labels1 = ax.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines1 + lines2, labels1 + labels2, loc='best', fontsize=9)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Store results\n",
    "        quality_trend_coef = reg_quality.coef_[1] if len(reg_quality.coef_) > 1 else reg_quality.coef_[0]\n",
    "        time_coef = float(reg_time.coef_[0])\n",
    "        \n",
    "        regression_results.append({\n",
    "            'algorithm': algo,\n",
    "            'quality_r2': r2_quality,\n",
    "            'time_r2': r2_time,\n",
    "            'quality_trend': 'decreasing' if quality_trend_coef < 0 else 'increasing',\n",
    "            'time_complexity': f\"O(n^{time_coef:.2f})\" if time_coef > 0 else 'O(1)'\n",
    "        })\n",
    "    \n",
    "    # Summary table\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"REGRESSION ANALYSIS - PERFORMANCE MODELING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    reg_df = pd.DataFrame(regression_results)\n",
    "    for _, row in reg_df.iterrows():\n",
    "        print(f\"\\n{row['algorithm']}:\")\n",
    "        print(f\"  Quality: R² = {row['quality_r2']:.3f} (trend: {row['quality_trend']})\")\n",
    "        print(f\"  Time: R² = {row['time_r2']:.3f} (estimated complexity: {row['time_complexity']})\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"INTERPRETATION:\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"R² close to 1 = model predicts data well\")\n",
    "    print(\"R² < 0.5 = unreliable model, variable performance\")\n",
    "    print(\"Estimated complexity gives an idea of algorithm scalability\")\n",
    "else:\n",
    "    print(\"results_df not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# VISUALISATION DE L'IMPACT DES HYPERPARAMÈTRES\n",
    "# =============================================================================\n",
    "\n",
    "def visualize_hyperparameter_impact(cv_results, param_grid):\n",
    "    \"\"\"\n",
    "    Visualizes the impact of each hyperparameter on performance.\n",
    "    \n",
    "    Creates a chart per hyperparameter showing:\n",
    "    - Average score with error bars (95% CI)\n",
    "    - Performance trend\n",
    "    \n",
    "    Args:\n",
    "        cv_results: DataFrame resulting from knapsack_cross_validation\n",
    "        param_grid: Dict of parameter grid\n",
    "    \"\"\"\n",
    "    \n",
    "    if cv_results is None or len(cv_results) == 0:\n",
    "        print(\"No results to visualize\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"HYPERPARAMETERS IMPACT VISUALIZATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    param_names = list(param_grid.keys())\n",
    "    n_params = len(param_names)\n",
    "    \n",
    "    # Créer subplots\n",
    "    fig, axes = plt.subplots(1, n_params, figsize=(6*n_params, 5))\n",
    "    \n",
    "    if n_params == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, param_name in enumerate(param_names):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Grouper par valeur de ce paramètre\n",
    "        grouped = cv_results.groupby(param_name).agg({\n",
    "            'mean_score': 'mean',\n",
    "            'std_score': 'mean',\n",
    "            'ci_95': 'mean'\n",
    "        }).reset_index()\n",
    "        \n",
    "        grouped = grouped.sort_values(param_name)\n",
    "        \n",
    "        # Plot with error bars\n",
    "        x = grouped[param_name]\n",
    "        y = grouped['mean_score']\n",
    "        yerr = grouped['ci_95']\n",
    "        \n",
    "        # Barplot\n",
    "        bars = ax.bar(range(len(x)), y, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "        \n",
    "        # Error bars (95% CI)\n",
    "        ax.errorbar(range(len(x)), y, yerr=yerr, fmt='none', \n",
    "                   ecolor='black', capsize=5, capthick=2)\n",
    "        \n",
    "        # Color according to performance\n",
    "        colors = []\n",
    "        max_score = y.max()\n",
    "        for score in y:\n",
    "            if score >= max_score * 0.98:\n",
    "                colors.append('darkgreen')\n",
    "            elif score >= max_score * 0.95:\n",
    "                colors.append('green')\n",
    "            elif score >= max_score * 0.90:\n",
    "                colors.append('orange')\n",
    "            else:\n",
    "                colors.append('red')\n",
    "        \n",
    "        for bar, color in zip(bars, colors):\n",
    "            bar.set_facecolor(color)\n",
    "        \n",
    "        # Labels\n",
    "        ax.set_xticks(range(len(x)))\n",
    "        ax.set_xticklabels([f'{val}' for val in x], rotation=45 if len(x) > 5 else 0)\n",
    "        ax.set_xlabel(param_name.replace('_', ' ').title(), fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Score Moyen', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Impact de {param_name}\\n(Barres = IC 95%)', \n",
    "                    fontsize=12, fontweight='bold')\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        \n",
    "        # Trouver la meilleure valeur\n",
    "        best_idx = y.idxmax()\n",
    "        best_val = x.iloc[best_idx]\n",
    "        ax.axvline(best_idx, color='red', linestyle='--', linewidth=2, \n",
    "                  alpha=0.5, label=f'Meilleur: {best_val}')\n",
    "        ax.legend()\n",
    "    \n",
    "    plt.suptitle('Hyperparameters Sensitivity Analysis', \n",
    "                fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistiques d'impact\n",
    "    print(\"\\nRELATIVE IMPACT OF HYPERPARAMETERS:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for param_name in param_names:\n",
    "        grouped = cv_results.groupby(param_name)['mean_score']\n",
    "        \n",
    "        min_score = grouped.mean().min()\n",
    "        max_score = grouped.mean().max()\n",
    "        impact_pct = ((max_score - min_score) / min_score) * 100\n",
    "        \n",
    "        importance = \"TRÈS IMPORTANT\" if impact_pct > 5 else \\\n",
    "                    \"IMPORTANT\" if impact_pct > 2 else \\\n",
    "                    \"MODÉRÉ\" if impact_pct > 0.5 else \\\n",
    "                    \"FAIBLE\"\n",
    "        \n",
    "        print(f\"{param_name:25s}: Impact = {impact_pct:5.2f}% | {importance}\")\n",
    "        print(f\"Meilleure valeur: {grouped.mean().idxmax()}\")\n",
    "        print(f\"Score range: [{min_score:.1f}, {max_score:.1f}]\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# COMPARAISON PARAMÈTRES FIXES vs OPTIMISÉS\n",
    "# =============================================================================\n",
    "\n",
    "def compare_default_vs_optimized(algorithm_func, problems, default_params, \n",
    "                                 optimized_params, n_runs=10, random_state=42):\n",
    "    \"\"\"\n",
    "    Compare les performances avec paramètres par défaut vs optimisés.\n",
    "    \n",
    "    Utilise un test statistique (Wilcoxon) pour déterminer si la différence\n",
    "    est significative.\n",
    "    \n",
    "    Args:\n",
    "        algorithm_func: Fonction de l'algorithme\n",
    "        problems: Liste de Problem instances\n",
    "        default_params: Dict des paramètres par défaut\n",
    "        optimized_params: Dict des paramètres optimisés (de la CV)\n",
    "        n_runs: Nombre de répétitions par configuration\n",
    "        random_state: Seed\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame avec résultats détaillés\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy.stats import wilcoxon\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARAISON: PARAMÈTRES FIXES vs OPTIMISÉS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Algorithme: {algorithm_func.__name__}\")\n",
    "    print(f\"Number of problems: {len(problems)}\")\n",
    "    print(f\"Répétitions par config: {n_runs}\")\n",
    "    print()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for prob_idx, problem in enumerate(problems):\n",
    "        print(f\"\\n[Problème {prob_idx+1}/{len(problems)}] n={problem.n}, capacity={problem.capacity}\")\n",
    "        \n",
    "        # Scores avec paramètres par défaut\n",
    "        default_scores = []\n",
    "        default_times = []\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "            seed = random_state + run\n",
    "            try:\n",
    "                import time as time_module\n",
    "                start = time_module.time()\n",
    "                sol = algorithm_func(problem, **default_params, seed=seed)\n",
    "                elapsed = time_module.time() - start\n",
    "                \n",
    "                if sol is not None:\n",
    "                    default_scores.append(sol.total_value)\n",
    "                    default_times.append(elapsed * 1000)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Scores avec paramètres optimisés\n",
    "        optimized_scores = []\n",
    "        optimized_times = []\n",
    "        \n",
    "        for run in range(n_runs):\n",
    "            seed = random_state + run\n",
    "            try:\n",
    "                import time as time_module\n",
    "                start = time_module.time()\n",
    "                sol = algorithm_func(problem, **optimized_params, seed=seed)\n",
    "                elapsed = time_module.time() - start\n",
    "                \n",
    "                if sol is not None:\n",
    "                    optimized_scores.append(sol.total_value)\n",
    "                    optimized_times.append(elapsed * 1000)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if len(default_scores) > 0 and len(optimized_scores) > 0:\n",
    "            # Statistiques\n",
    "            default_mean = np.mean(default_scores)\n",
    "            optimized_mean = np.mean(optimized_scores)\n",
    "            \n",
    "            improvement_pct = ((optimized_mean - default_mean) / default_mean) * 100\n",
    "            \n",
    "            # Test de Wilcoxon (paired test)\n",
    "            if len(default_scores) == len(optimized_scores) and len(default_scores) >= 5:\n",
    "                stat, p_value = wilcoxon(default_scores, optimized_scores)\n",
    "                is_significant = p_value < 0.05\n",
    "            else:\n",
    "                p_value = None\n",
    "                is_significant = None\n",
    "            \n",
    "            print(f\"  Default:   {default_mean:.2f} ± {np.std(default_scores):.2f}\")\n",
    "            print(f\"  Optimized: {optimized_mean:.2f} ± {np.std(optimized_scores):.2f}\")\n",
    "            print(f\"  → Amélioration: {improvement_pct:+.2f}%\", end='')\n",
    "            \n",
    "            if is_significant is not None:\n",
    "                if is_significant:\n",
    "                    print(f\" (p={p_value:.4f}) ✓ SIGNIFICATIF\")\n",
    "                else:\n",
    "                    print(f\" (p={p_value:.4f}) ✗ Non significatif\")\n",
    "            else:\n",
    "                print()\n",
    "            \n",
    "            results.append({\n",
    "                'n': problem.n,\n",
    "                'capacity': problem.capacity,\n",
    "                'default_mean': default_mean,\n",
    "                'default_std': np.std(default_scores),\n",
    "                'optimized_mean': optimized_mean,\n",
    "                'optimized_std': np.std(optimized_scores),\n",
    "                'improvement_pct': improvement_pct,\n",
    "                'default_time_ms': np.mean(default_times),\n",
    "                'optimized_time_ms': np.mean(optimized_times),\n",
    "                'p_value': p_value,\n",
    "                'is_significant': is_significant\n",
    "            })\n",
    "    \n",
    "    # Résumé global\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RÉSUMÉ GLOBAL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    overall_improvement = results_df['improvement_pct'].mean()\n",
    "    n_significant = results_df['is_significant'].sum() if 'is_significant' in results_df else 0\n",
    "    n_total = len(results_df)\n",
    "    \n",
    "    print(f\"\\nAmélioration moyenne: {overall_improvement:+.2f}%\")\n",
    "    print(f\"Améliorations significatives: {n_significant}/{n_total} problèmes\")\n",
    "    \n",
    "    if overall_improvement > 0:\n",
    "        print(f\"\\n✓ Optimized parameters improve performance by {overall_improvement:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\n✗ Les paramètres optimisés n'améliorent pas la performance\")\n",
    "    \n",
    "    # Visualisation\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Graphique 1: Comparaison des scores\n",
    "    ax = axes[0]\n",
    "    x = np.arange(len(results_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, results_df['default_mean'], width, \n",
    "                  label='Paramètres par défaut', alpha=0.7, color='orange',\n",
    "                  yerr=results_df['default_std'], capsize=5)\n",
    "    bars2 = ax.bar(x + width/2, results_df['optimized_mean'], width,\n",
    "                  label='Paramètres optimisés', alpha=0.7, color='green',\n",
    "                  yerr=results_df['optimized_std'], capsize=5)\n",
    "    \n",
    "    ax.set_xlabel('Problème', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Score Moyen', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Comparaison des Scores\\n(Barres d\\'erreur = std)', \n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([f'n={n}' for n in results_df['n']], rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Graphique 2: % d'amélioration\n",
    "    ax = axes[1]\n",
    "    colors = ['green' if imp > 0 else 'red' for imp in results_df['improvement_pct']]\n",
    "    bars = ax.barh(range(len(results_df)), results_df['improvement_pct'], \n",
    "                  color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    ax.set_yticks(range(len(results_df)))\n",
    "    ax.set_yticklabels([f'n={n}' for n in results_df['n']])\n",
    "    ax.set_xlabel('Amélioration (%)', fontsize=12, fontweight='bold')\n",
    "    ax.set_title('Amélioration par Problème\\n(Vert=Amélioration, Rouge=Dégradation)',\n",
    "                fontsize=13, fontweight='bold')\n",
    "    ax.axvline(0, color='black', linestyle='-', linewidth=1)\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
